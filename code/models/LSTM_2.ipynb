{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19332,
     "status": "ok",
     "timestamp": 1732687090378,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "y2HfIn_mP2Pd",
    "outputId": "daf85896-d337-4ff7-9725-4bae00f96f88"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732687090379,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "iYzznQU9QRE5"
   },
   "outputs": [],
   "source": [
    "def split_get_label_from_filename(filename):\n",
    "    return label_mapping.get(filename[8:-5],-1)\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    match = re.search(r'_(\\d+_?\\d*)\\.json$', filename)\n",
    "    print(match)\n",
    "    if match:\n",
    "        label_key = match.group(1)\n",
    "        return label_mapping.get(label_key, -1)  # 如果标签不匹配返回 -1\n",
    "\n",
    "# 获取文件夹中的文件及其标签\n",
    "def load_files_and_labels(folder_path,split=False):\n",
    "    file_list = []\n",
    "    labels = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        # print(\"file: \", file)\n",
    "        if file.endswith(\".json\"):\n",
    "            if split:\n",
    "                label = split_get_label_from_filename(file)\n",
    "            else: label = get_label_from_filename(file)\n",
    "            if label != -1:\n",
    "                file_list.append(os.path.join(folder_path, file))\n",
    "                labels.append(label)\n",
    "            #print(f\"File: {file}, Label: {label}\")\n",
    "\n",
    "    return file_list, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732687090379,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "wI5Wdf6hUjU5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. 提取字符并编码为整数索引\n",
    "def hex_to_sequence(hex_feature):\n",
    "    \"\"\"\n",
    "    将十六进制字符串转换为整数索引序列。\n",
    "    去掉冒号并转换为字符对应的索引。\n",
    "    \"\"\"\n",
    "    hex_chars = hex_feature.replace(\":\", \"\")\n",
    "    char_to_index = {char: idx for idx, char in enumerate(\"0123456789abcdef\")}\n",
    "    return [char_to_index[char] for char in hex_chars]\n",
    "\n",
    "def process_json(file_path):\n",
    "    \"\"\"\n",
    "    处理 JSON 文件，提取时间戳、包长度和 raw data 特征，并对特征进行归一化。\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        # 打开 JSON 文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            datas = json.load(file)\n",
    "\n",
    "        # 遍历 JSON 数据，提取时间戳和包长度\n",
    "        initial_timestamp = None\n",
    "        for data in datas:\n",
    "            try:\n",
    "                timestamp = float(data[\"_source\"][\"layers\"][\"frame\"][\"frame.time_relative\"])  # 时间戳\n",
    "                packet_length = int(data[\"_source\"][\"layers\"][\"frame\"][\"frame.len\"])  # 包长度\n",
    "\n",
    "                # 获取数据部分，若不存在则为0\n",
    "                # if 'data' in data[\"_source\"][\"layers\"]:\n",
    "                #     rawdata = data[\"_source\"][\"layers\"][\"data\"][\"data.data\"]\n",
    "                # else:\n",
    "                #     rawdata = '0'\n",
    "\n",
    "                # # 将原始数据转换为整数序列\n",
    "                # data_feature = hex_to_sequence(rawdata)\n",
    "\n",
    "                # 将数据填充或截断为指定长度 2832\n",
    "                # if len(data_feature) < 2832:  # 如果长度小于 2832，填充 0\n",
    "                #     data_feature += [0] * (2832 - len(data_feature))\n",
    "                # elif len(data_feature) > 2832:  # 如果长度大于 2832，截断\n",
    "                #     data_feature = data_feature[:2832]\n",
    "\n",
    "                # 如果数据长度不符合预期，打印出来\n",
    "                # if len(data_feature) != 2832:\n",
    "                #     print(f\"Data feature length mismatch: {len(data_feature)}\")\n",
    "\n",
    "                # 初始化时间戳\n",
    "                if initial_timestamp is None:\n",
    "                    initial_timestamp = timestamp  # 设置初始时间戳\n",
    "\n",
    "                # 计算相对时间戳\n",
    "                relative_timestamp = timestamp - initial_timestamp\n",
    "                # print(type(relative_timestamp))\n",
    "\n",
    "\n",
    "                timestamp_array = np.array([relative_timestamp], dtype=float)\n",
    "                packet_length_array = np.array([packet_length], dtype=float)/1512\n",
    "                # data_feature = np.array(data_feature, dtype=float)/15\n",
    "           \n",
    "                # 将特征按顺序组合为 [时间戳, 包长度, 数据特征]\n",
    "                feature = np.hstack((timestamp_array, packet_length_array))#,data_feature\n",
    "                \n",
    "                # 添加到特征列表\n",
    "                features.append(feature)\n",
    "\n",
    "            except (KeyError, ValueError) as e:\n",
    "                # 跳过有问题的数据包\n",
    "                print(f\"Skipping packet due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        features_array=np.array(features)\n",
    "        max_timestamp = np.max(features_array[:, 0])  # 获取最大时间戳\n",
    "        # print(\"max\")\n",
    "        features_array[:, 0] = [feature[0] / max_timestamp for feature in features_array]  # 时间戳归一化\n",
    "        # print(\"11\") \n",
    "\n",
    "    except Exception as e:\n",
    "        print(Exception)\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        features_array = np.zeros((1, 2))  # 返回空特征以避免程序中断\n",
    "\n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732687099234,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "Z2EwyTe2QRM7",
    "outputId": "aceeb311-cc3d-492e-b05f-c940c6421672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "<class 'list'>\n",
      "(300,)\n",
      "[2 1 1 1 2 1 0 3 0 2 2 2 0 3 0 3 0 2 1 2 3 0 3 0 3 2 1 0 0 3 2 3 1 1 3 3 3\n",
      " 1 1 2 3 1 2 3 0 2 0 0 2 3 3 2 1 2 0 1 0 2 0 0 3 3 0 3 3 2 1 3 2 1 2 0 2 2\n",
      " 2 1 2 1 3 0 3 2 1 2 2 1 2 0 0 0 3 2 3 2 2 1 3 1 0 3 0 1 0 2 2 3 3 0 2 0 0\n",
      " 2 0 0 1 0 2 3 2 0 3 0 3 1 2 2 1 1 1 0 0 3 1 0 3 0 0 1 3 1 3 3 0 2 1 0 3 1\n",
      " 2 3 1 2 3 0 3 1 1 2 2 1 2 1 3 0 0 0 0 0 0 0 0 3 3 2 2 3 3 3 2 1 3 1 2 1 1\n",
      " 3 1 2 1 2 2 1 3 2 1 3 2 0 0 3 2 2 1 1 0 1 2 0 1 3 3 0 1 1 1 2 3 1 3 3 3 3\n",
      " 2 2 1 2 3 3 0 0 0 3 1 3 2 1 0 2 0 2 3 1 1 2 0 0 1 2 0 1 2 1 2 2 1 2 3 1 1\n",
      " 2 2 1 0 3 0 0 0 1 0 3 1 0 1 1 1 0 3 3 0 1 0 3 3 0 0 3 2 2 1 3 0 3 0 2 3 1\n",
      " 3 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 定义文件夹路径 /content/drive/MyDrive/202_project/202_packet_json\n",
    "\n",
    "split = True\n",
    "# folder_path = \"packet_json_split\"\n",
    "if split:\n",
    "    folder_path = \"packet_json_split\" \n",
    "else:\n",
    "    folder_path = \"202_packet_json_new\"\n",
    "\n",
    "# 定义标签映射\n",
    "label_mapping = {\n",
    "    \"0\": 0,             # static\n",
    "    \"0_2\": 1,           # slightly_move\n",
    "    \"1\": 2,             # move\n",
    "    \"4\": 3              # intensely_move\n",
    "}\n",
    "\n",
    "# 调用函数获取文件和标签\n",
    "data_paths, labels = load_files_and_labels(folder_path,split)\n",
    "# 用于存储每个样本的特征\n",
    "\n",
    "print(type(labels))\n",
    "labels_array=np.array(labels)#[:50]\n",
    "print(labels_array.shape)\n",
    "print(labels_array)\n",
    "labels_tensor=torch.tensor(labels_array,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOHv4juYLBvy",
    "outputId": "251914c5-78b3-4e69-a9a1-cebaf2fc923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet_json_split/b3_p2_2_1.json\n",
      "(3136, 2)\n",
      "packet_json_split/b1_p3_2_0_2.json\n",
      "(2915, 2)\n",
      "packet_json_split/b1_p1_2_0_2.json\n",
      "(3317, 2)\n",
      "packet_json_split/b3_p3_3_0_2.json\n",
      "(3301, 2)\n",
      "packet_json_split/b1_p1_2_1.json\n",
      "(2990, 2)\n",
      "packet_json_split/b2_p2_2_0_2.json\n",
      "(3084, 2)\n",
      "packet_json_split/b3_p1_2_0.json\n",
      "(3552, 2)\n",
      "packet_json_split/b5_p4_3_4.json\n",
      "(3431, 2)\n",
      "packet_json_split/b4_p1_3_0.json\n",
      "(3336, 2)\n",
      "packet_json_split/b1_p3_2_1.json\n",
      "(2711, 2)\n",
      "packet_json_split/b2_p5_1_1.json\n",
      "(3710, 2)\n",
      "packet_json_split/b5_p4_1_1.json\n",
      "(3420, 2)\n",
      "packet_json_split/b3_p5_1_0.json\n",
      "(3552, 2)\n",
      "packet_json_split/b1_p5_1_4.json\n",
      "(3081, 2)\n",
      "packet_json_split/b3_p3_1_0.json\n",
      "(3188, 2)\n",
      "packet_json_split/b1_p3_2_4.json\n",
      "(2883, 2)\n",
      "packet_json_split/b3_p3_2_0.json\n",
      "(3486, 2)\n",
      "packet_json_split/b5_p4_3_1.json\n",
      "(3326, 2)\n",
      "packet_json_split/b2_p5_2_0_2.json\n",
      "(3516, 2)\n",
      "packet_json_split/b1_p3_1_1.json\n",
      "(2635, 2)\n",
      "packet_json_split/b3_p1_1_4.json\n",
      "(3297, 2)\n",
      "packet_json_split/b2_p1_1_0.json\n",
      "(3035, 2)\n",
      "packet_json_split/b3_p5_1_4.json\n",
      "(2870, 2)\n",
      "packet_json_split/b1_p1_2_0.json\n",
      "(2903, 2)\n",
      "packet_json_split/b1_p5_2_4.json\n",
      "(3103, 2)\n",
      "packet_json_split/b4_p4_2_1.json\n",
      "(3314, 2)\n",
      "packet_json_split/b2_p3_1_0_2.json\n",
      "(3381, 2)\n",
      "packet_json_split/b1_p1_3_0.json\n",
      "(2979, 2)\n",
      "packet_json_split/b1_p4_3_0.json\n",
      "(2881, 2)\n",
      "packet_json_split/b5_p5_2_4.json\n",
      "(3015, 2)\n",
      "packet_json_split/b5_p4_2_1.json\n",
      "(3325, 2)\n",
      "packet_json_split/b4_p4_3_4.json\n",
      "(3078, 2)\n",
      "packet_json_split/b5_p5_1_0_2.json\n",
      "(3379, 2)\n",
      "packet_json_split/b3_p3_1_0_2.json\n",
      "(3697, 2)\n",
      "packet_json_split/b5_p3_1_4.json\n",
      "(3097, 2)\n",
      "packet_json_split/b4_p1_1_4.json\n",
      "(3302, 2)\n",
      "packet_json_split/b2_p4_3_4.json\n",
      "(3463, 2)\n",
      "packet_json_split/b3_p5_3_0_2.json\n",
      "(3476, 2)\n",
      "packet_json_split/b1_p5_2_0_2.json\n",
      "(3115, 2)\n",
      "packet_json_split/b4_p5_1_1.json\n",
      "(3260, 2)\n",
      "packet_json_split/b2_p1_3_4.json\n",
      "(3272, 2)\n",
      "packet_json_split/b3_p2_3_0_2.json\n",
      "(3310, 2)\n",
      "packet_json_split/b4_p5_3_1.json\n",
      "(3341, 2)\n",
      "packet_json_split/b2_p2_2_4.json\n",
      "(3609, 2)\n",
      "packet_json_split/b5_p1_2_0.json\n",
      "(3055, 2)\n",
      "packet_json_split/b1_p1_3_1.json\n",
      "(2969, 2)\n",
      "packet_json_split/b3_p4_1_0.json\n",
      "(3437, 2)\n",
      "packet_json_split/b4_p3_1_0.json\n",
      "(3350, 2)\n",
      "packet_json_split/b3_p1_3_1.json\n",
      "(3495, 2)\n",
      "packet_json_split/b1_p3_1_4.json\n",
      "(2921, 2)\n",
      "packet_json_split/b4_p5_3_4.json\n",
      "(3461, 2)\n",
      "packet_json_split/b2_p1_2_1.json\n",
      "(3440, 2)\n",
      "packet_json_split/b3_p4_2_0_2.json\n",
      "(3346, 2)\n",
      "packet_json_split/b2_p5_3_1.json\n",
      "(3593, 2)\n",
      "packet_json_split/b2_p4_3_0.json\n",
      "(3496, 2)\n",
      "packet_json_split/b4_p1_2_0_2.json\n",
      "(3485, 2)\n",
      "packet_json_split/b2_p2_2_0.json\n",
      "(3344, 2)\n",
      "packet_json_split/b1_p5_2_1.json\n",
      "(2864, 2)\n",
      "packet_json_split/b5_p3_2_0.json\n",
      "(3213, 2)\n",
      "packet_json_split/b4_p4_1_0.json\n",
      "(3163, 2)\n",
      "packet_json_split/b2_p4_2_4.json\n",
      "(3348, 2)\n",
      "packet_json_split/b4_p2_1_4.json\n",
      "(3501, 2)\n",
      "packet_json_split/b4_p5_3_0.json\n",
      "(3353, 2)\n",
      "packet_json_split/b3_p4_3_4.json\n",
      "(3428, 2)\n",
      "packet_json_split/b3_p5_3_4.json\n",
      "(3005, 2)\n",
      "packet_json_split/b4_p2_1_1.json\n",
      "(3126, 2)\n",
      "packet_json_split/b2_p2_1_0_2.json\n",
      "(3335, 2)\n",
      "packet_json_split/b2_p1_2_4.json\n",
      "(3140, 2)\n",
      "packet_json_split/b2_p5_2_1.json\n",
      "(3341, 2)\n",
      "packet_json_split/b5_p1_2_0_2.json\n",
      "(3147, 2)\n",
      "packet_json_split/b5_p2_3_1.json\n",
      "(2908, 2)\n",
      "packet_json_split/b5_p3_1_0.json\n",
      "(3075, 2)\n",
      "packet_json_split/b1_p5_3_1.json\n",
      "(2854, 2)\n",
      "packet_json_split/b5_p1_1_1.json\n",
      "(3274, 2)\n",
      "packet_json_split/b2_p2_3_1.json\n",
      "(3751, 2)\n",
      "packet_json_split/b1_p4_1_0_2.json\n",
      "(2653, 2)\n",
      "packet_json_split/b3_p3_2_1.json\n",
      "(3470, 2)\n",
      "packet_json_split/b4_p1_3_0_2.json\n",
      "(3083, 2)\n",
      "packet_json_split/b1_p2_1_4.json\n",
      "(2901, 2)\n",
      "packet_json_split/b5_p4_3_0.json\n",
      "(3543, 2)\n",
      "packet_json_split/b2_p3_2_4.json\n",
      "(3154, 2)\n",
      "packet_json_split/b2_p1_3_1.json\n",
      "(3739, 2)\n",
      "packet_json_split/b1_p1_3_0_2.json\n",
      "(3077, 2)\n",
      "packet_json_split/b4_p1_1_1.json\n",
      "(3424, 2)\n",
      "packet_json_split/b4_p3_1_1.json\n",
      "(3294, 2)\n",
      "packet_json_split/b5_p1_1_0_2.json\n",
      "(3366, 2)\n",
      "packet_json_split/b1_p4_1_1.json\n",
      "(2869, 2)\n",
      "packet_json_split/b5_p3_3_0.json\n",
      "(3115, 2)\n",
      "packet_json_split/b2_p5_1_0.json\n",
      "(3263, 2)\n",
      "packet_json_split/b1_p5_3_0.json\n",
      "(3091, 2)\n",
      "packet_json_split/b4_p5_1_4.json\n",
      "(3123, 2)\n",
      "packet_json_split/b2_p4_3_1.json\n",
      "(3491, 2)\n",
      "packet_json_split/b1_p5_3_4.json\n",
      "(3073, 2)\n",
      "packet_json_split/b4_p4_1_1.json\n",
      "(3199, 2)\n",
      "packet_json_split/b5_p2_1_1.json\n",
      "(2791, 2)\n",
      "packet_json_split/b5_p4_3_0_2.json\n",
      "(3149, 2)\n",
      "packet_json_split/b5_p5_1_4.json\n",
      "(3095, 2)\n",
      "packet_json_split/b2_p5_3_0_2.json\n",
      "(3093, 2)\n",
      "packet_json_split/b2_p3_1_0.json\n",
      "(3188, 2)\n",
      "packet_json_split/b5_p5_3_4.json\n",
      "(3051, 2)\n",
      "packet_json_split/b5_p1_1_0.json\n",
      "(3013, 2)\n",
      "packet_json_split/b4_p5_1_0_2.json\n",
      "(3213, 2)\n",
      "packet_json_split/b3_p1_1_0.json\n",
      "(3312, 2)\n",
      "packet_json_split/b1_p1_1_1.json\n",
      "(2920, 2)\n",
      "packet_json_split/b1_p4_3_1.json\n",
      "(2844, 2)\n",
      "packet_json_split/b3_p2_1_4.json\n",
      "(3522, 2)\n",
      "packet_json_split/b1_p4_2_4.json\n",
      "(2758, 2)\n",
      "packet_json_split/b3_p2_1_0.json\n",
      "(3294, 2)\n",
      "packet_json_split/b4_p5_2_1.json\n",
      "(3414, 2)\n",
      "packet_json_split/b4_p4_2_0.json\n",
      "(3394, 2)\n",
      "packet_json_split/b5_p5_2_0.json\n",
      "(3386, 2)\n",
      "packet_json_split/b1_p2_3_1.json\n",
      "(2814, 2)\n",
      "packet_json_split/b3_p5_2_0.json\n",
      "(3691, 2)\n",
      "packet_json_split/b5_p4_2_0.json\n",
      "(3784, 2)\n",
      "packet_json_split/b4_p3_2_0_2.json\n",
      "(3089, 2)\n",
      "packet_json_split/b2_p3_3_0.json\n",
      "(3252, 2)\n",
      "packet_json_split/b4_p3_2_1.json\n",
      "(3237, 2)\n",
      "packet_json_split/b5_p4_2_4.json\n",
      "(3313, 2)\n",
      "packet_json_split/b2_p2_1_1.json\n",
      "(3400, 2)\n",
      "packet_json_split/b5_p1_3_0.json\n",
      "(3036, 2)\n",
      "packet_json_split/b4_p2_2_4.json\n",
      "(3374, 2)\n",
      "packet_json_split/b2_p5_3_0.json\n",
      "(3523, 2)\n",
      "packet_json_split/b3_p2_3_4.json\n",
      "(3294, 2)\n",
      "packet_json_split/b2_p3_2_0_2.json\n",
      "(3257, 2)\n",
      "packet_json_split/b5_p3_1_1.json\n",
      "(3182, 2)\n",
      "packet_json_split/b3_p3_1_1.json\n",
      "(3154, 2)\n",
      "packet_json_split/b3_p1_2_0_2.json\n",
      "(3557, 2)\n",
      "packet_json_split/b1_p2_1_0_2.json\n",
      "(3008, 2)\n",
      "packet_json_split/b2_p3_3_0_2.json\n",
      "(3549, 2)\n",
      "packet_json_split/b3_p3_3_0.json\n",
      "(3252, 2)\n",
      "packet_json_split/b3_p5_3_0.json\n",
      "(3591, 2)\n",
      "packet_json_split/b5_p4_1_4.json\n",
      "(3372, 2)\n",
      "packet_json_split/b2_p4_1_0_2.json\n",
      "(3300, 2)\n",
      "packet_json_split/b2_p3_2_0.json\n",
      "(3486, 2)\n",
      "packet_json_split/b4_p1_3_4.json\n",
      "(3603, 2)\n",
      "packet_json_split/b4_p2_2_0.json\n",
      "(3132, 2)\n",
      "packet_json_split/b1_p5_1_0.json\n",
      "(3062, 2)\n",
      "packet_json_split/b4_p5_2_0_2.json\n",
      "(3094, 2)\n",
      "packet_json_split/b5_p1_3_4.json\n",
      "(3119, 2)\n",
      "packet_json_split/b2_p1_1_0_2.json\n",
      "(3676, 2)\n",
      "packet_json_split/b4_p3_3_4.json\n",
      "(3187, 2)\n",
      "packet_json_split/b5_p2_3_4.json\n",
      "(3221, 2)\n",
      "packet_json_split/b4_p3_2_0.json\n",
      "(3595, 2)\n",
      "packet_json_split/b5_p2_2_1.json\n",
      "(2902, 2)\n",
      "packet_json_split/b5_p4_2_0_2.json\n",
      "(3158, 2)\n",
      "packet_json_split/b5_p5_3_0.json\n",
      "(3231, 2)\n",
      "packet_json_split/b3_p3_2_4.json\n",
      "(3287, 2)\n",
      "packet_json_split/b5_p3_2_0_2.json\n",
      "(3080, 2)\n",
      "packet_json_split/b3_p2_1_1.json\n",
      "(3221, 2)\n",
      "packet_json_split/b1_p4_1_4.json\n",
      "(2706, 2)\n",
      "packet_json_split/b1_p2_3_0_2.json\n",
      "(2949, 2)\n",
      "packet_json_split/b3_p5_3_1.json\n",
      "(2936, 2)\n",
      "packet_json_split/b4_p4_1_4.json\n",
      "(3219, 2)\n",
      "packet_json_split/b5_p2_2_0.json\n",
      "(3173, 2)\n",
      "packet_json_split/b2_p4_1_4.json\n",
      "(3222, 2)\n",
      "packet_json_split/b5_p2_2_0_2.json\n",
      "(3030, 2)\n",
      "packet_json_split/b4_p2_2_0_2.json\n",
      "(3152, 2)\n",
      "packet_json_split/b5_p1_3_1.json\n",
      "(3153, 2)\n",
      "packet_json_split/b2_p1_1_1.json\n",
      "(3669, 2)\n",
      "packet_json_split/b1_p4_3_0_2.json\n",
      "(3053, 2)\n",
      "packet_json_split/b3_p1_2_1.json\n",
      "(3681, 2)\n",
      "packet_json_split/b3_p1_3_0_2.json\n",
      "(3481, 2)\n",
      "packet_json_split/b4_p3_1_4.json\n",
      "(3173, 2)\n",
      "packet_json_split/b2_p1_3_0.json\n",
      "(2801, 2)\n",
      "packet_json_split/b1_p2_3_0.json\n",
      "(2997, 2)\n",
      "packet_json_split/b5_p2_1_0.json\n",
      "(3448, 2)\n",
      "packet_json_split/b1_p2_1_0.json\n",
      "(2972, 2)\n",
      "packet_json_split/b2_p1_2_0.json\n",
      "(3094, 2)\n",
      "packet_json_split/b5_p5_1_0.json\n",
      "(3258, 2)\n",
      "packet_json_split/b2_p2_3_0.json\n",
      "(2925, 2)\n",
      "packet_json_split/b3_p2_2_0.json\n",
      "(3653, 2)\n",
      "packet_json_split/b3_p5_2_4.json\n",
      "(2940, 2)\n",
      "packet_json_split/b4_p4_2_4.json\n",
      "(3155, 2)\n",
      "packet_json_split/b4_p3_3_1.json\n",
      "(3284, 2)\n",
      "packet_json_split/b1_p2_2_1.json\n",
      "(2823, 2)\n",
      "packet_json_split/b2_p3_3_4.json\n",
      "(3607, 2)\n",
      "packet_json_split/b5_p1_1_4.json\n",
      "(3170, 2)\n",
      "packet_json_split/b1_p2_3_4.json\n",
      "(2882, 2)\n",
      "packet_json_split/b1_p2_1_1.json\n",
      "(2745, 2)\n",
      "packet_json_split/b5_p4_1_0_2.json\n",
      "(3030, 2)\n",
      "packet_json_split/b3_p2_2_4.json\n",
      "(3522, 2)\n",
      "packet_json_split/b4_p2_3_0_2.json\n",
      "(3231, 2)\n",
      "packet_json_split/b1_p3_3_1.json\n",
      "(2762, 2)\n",
      "packet_json_split/b4_p4_2_0_2.json\n",
      "(3332, 2)\n",
      "packet_json_split/b2_p4_3_0_2.json\n",
      "(3265, 2)\n",
      "packet_json_split/b3_p3_3_4.json\n",
      "(3379, 2)\n",
      "packet_json_split/b1_p1_1_0_2.json\n",
      "(3279, 2)\n",
      "packet_json_split/b2_p4_2_1.json\n",
      "(3352, 2)\n",
      "packet_json_split/b2_p4_2_0_2.json\n",
      "(3388, 2)\n",
      "packet_json_split/b5_p5_3_1.json\n",
      "(3273, 2)\n",
      "packet_json_split/b2_p3_3_1.json\n",
      "(2804, 2)\n",
      "packet_json_split/b5_p2_3_0_2.json\n",
      "(3037, 2)\n",
      "packet_json_split/b4_p2_3_4.json\n",
      "(3430, 2)\n",
      "packet_json_split/b5_p3_3_1.json\n",
      "(3181, 2)\n",
      "packet_json_split/b4_p3_1_0_2.json\n",
      "(3356, 2)\n",
      "packet_json_split/b1_p1_2_4.json\n",
      "(2935, 2)\n",
      "packet_json_split/b4_p1_2_1.json\n",
      "(3151, 2)\n",
      "packet_json_split/b4_p3_3_0.json\n",
      "(3202, 2)\n",
      "packet_json_split/b1_p2_2_0.json\n",
      "(2942, 2)\n",
      "packet_json_split/b4_p3_2_4.json\n",
      "(3281, 2)\n",
      "packet_json_split/b3_p4_3_1.json\n",
      "(3074, 2)\n",
      "packet_json_split/b4_p4_3_1.json\n",
      "(3084, 2)\n",
      "packet_json_split/b1_p5_1_0_2.json\n",
      "(3199, 2)\n",
      "packet_json_split/b3_p4_3_0_2.json\n",
      "(3120, 2)\n",
      "packet_json_split/b1_p4_1_0.json\n",
      "(3247, 2)\n",
      "packet_json_split/b4_p3_3_0_2.json\n",
      "(3179, 2)\n",
      "packet_json_split/b4_p2_3_1.json\n",
      "(3133, 2)\n",
      "packet_json_split/b4_p1_2_0.json\n",
      "(3364, 2)\n",
      "packet_json_split/b3_p1_1_0_2.json\n",
      "(3390, 2)\n",
      "packet_json_split/b5_p2_1_4.json\n",
      "(3353, 2)\n",
      "packet_json_split/b3_p1_2_4.json\n",
      "(3148, 2)\n",
      "packet_json_split/b2_p5_2_0.json\n",
      "(3552, 2)\n",
      "packet_json_split/b2_p1_3_0_2.json\n",
      "(3545, 2)\n",
      "packet_json_split/b3_p2_1_0_2.json\n",
      "(3168, 2)\n",
      "packet_json_split/b2_p2_3_0_2.json\n",
      "(3264, 2)\n",
      "packet_json_split/b3_p4_2_1.json\n",
      "(3302, 2)\n",
      "packet_json_split/b2_p5_2_4.json\n",
      "(3508, 2)\n",
      "packet_json_split/b4_p1_1_0_2.json\n",
      "(3062, 2)\n",
      "packet_json_split/b2_p2_1_4.json\n",
      "(3594, 2)\n",
      "packet_json_split/b2_p3_1_4.json\n",
      "(3352, 2)\n",
      "packet_json_split/b3_p3_1_4.json\n",
      "(3249, 2)\n",
      "packet_json_split/b1_p1_3_4.json\n",
      "(3088, 2)\n",
      "packet_json_split/b3_p5_2_1.json\n",
      "(3288, 2)\n",
      "packet_json_split/b4_p2_2_1.json\n",
      "(3023, 2)\n",
      "packet_json_split/b1_p4_2_0_2.json\n",
      "(2706, 2)\n",
      "packet_json_split/b4_p1_3_1.json\n",
      "(3271, 2)\n",
      "packet_json_split/b5_p1_2_4.json\n",
      "(3290, 2)\n",
      "packet_json_split/b3_p4_1_4.json\n",
      "(3338, 2)\n",
      "packet_json_split/b1_p4_2_0.json\n",
      "(2874, 2)\n",
      "packet_json_split/b3_p4_2_0.json\n",
      "(3424, 2)\n",
      "packet_json_split/b3_p2_3_0.json\n",
      "(3524, 2)\n",
      "packet_json_split/b2_p5_3_4.json\n",
      "(3239, 2)\n",
      "packet_json_split/b3_p5_1_0_2.json\n",
      "(3504, 2)\n",
      "packet_json_split/b1_p2_2_4.json\n",
      "(2995, 2)\n",
      "packet_json_split/b2_p2_2_1.json\n",
      "(3127, 2)\n",
      "packet_json_split/b3_p3_2_0_2.json\n",
      "(3568, 2)\n",
      "packet_json_split/b3_p1_3_0.json\n",
      "(3243, 2)\n",
      "packet_json_split/b5_p5_1_1.json\n",
      "(3401, 2)\n",
      "packet_json_split/b4_p4_3_0.json\n",
      "(3384, 2)\n",
      "packet_json_split/b3_p1_1_1.json\n",
      "(3251, 2)\n",
      "packet_json_split/b1_p1_1_4.json\n",
      "(2996, 2)\n",
      "packet_json_split/b4_p4_1_0_2.json\n",
      "(3239, 2)\n",
      "packet_json_split/b5_p3_3_0_2.json\n",
      "(3108, 2)\n",
      "packet_json_split/b3_p3_3_1.json\n",
      "(3200, 2)\n",
      "packet_json_split/b1_p3_3_0.json\n",
      "(3034, 2)\n",
      "packet_json_split/b1_p3_1_0.json\n",
      "(2979, 2)\n",
      "packet_json_split/b3_p2_2_0_2.json\n",
      "(3039, 2)\n",
      "packet_json_split/b5_p1_2_1.json\n",
      "(3281, 2)\n",
      "packet_json_split/b1_p5_2_0.json\n",
      "(2911, 2)\n",
      "packet_json_split/b5_p5_3_0_2.json\n",
      "(3291, 2)\n",
      "packet_json_split/b3_p4_1_1.json\n",
      "(3331, 2)\n",
      "packet_json_split/b5_p1_3_0_2.json\n",
      "(3228, 2)\n",
      "packet_json_split/b2_p4_1_1.json\n",
      "(3447, 2)\n",
      "packet_json_split/b1_p5_1_1.json\n",
      "(2831, 2)\n",
      "packet_json_split/b5_p2_1_0_2.json\n",
      "(3303, 2)\n",
      "packet_json_split/b3_p5_1_1.json\n",
      "(3593, 2)\n",
      "packet_json_split/b5_p2_2_4.json\n",
      "(3547, 2)\n",
      "packet_json_split/b2_p1_2_0_2.json\n",
      "(3525, 2)\n",
      "packet_json_split/b3_p5_2_0_2.json\n",
      "(3343, 2)\n",
      "packet_json_split/b1_p4_2_1.json\n",
      "(3044, 2)\n",
      "packet_json_split/b5_p5_2_1.json\n",
      "(3223, 2)\n",
      "packet_json_split/b1_p5_3_0_2.json\n",
      "(2968, 2)\n",
      "packet_json_split/b3_p4_3_0.json\n",
      "(3721, 2)\n",
      "packet_json_split/b2_p2_3_4.json\n",
      "(3507, 2)\n",
      "packet_json_split/b4_p5_1_0.json\n",
      "(3357, 2)\n",
      "packet_json_split/b4_p2_1_0.json\n",
      "(3109, 2)\n",
      "packet_json_split/b2_p2_1_0.json\n",
      "(3441, 2)\n",
      "packet_json_split/b4_p4_3_0_2.json\n",
      "(3254, 2)\n",
      "packet_json_split/b2_p4_1_0.json\n",
      "(3574, 2)\n",
      "packet_json_split/b1_p4_3_4.json\n",
      "(3045, 2)\n",
      "packet_json_split/b1_p2_2_0_2.json\n",
      "(2941, 2)\n",
      "packet_json_split/b5_p2_3_0.json\n",
      "(3318, 2)\n",
      "packet_json_split/b5_p3_1_0_2.json\n",
      "(3186, 2)\n",
      "packet_json_split/b1_p3_3_0_2.json\n",
      "(2979, 2)\n",
      "packet_json_split/b1_p3_1_0_2.json\n",
      "(2856, 2)\n",
      "packet_json_split/b4_p5_2_0.json\n",
      "(3425, 2)\n",
      "packet_json_split/b4_p1_2_4.json\n",
      "(3417, 2)\n",
      "packet_json_split/b1_p3_3_4.json\n",
      "(2782, 2)\n",
      "packet_json_split/b4_p1_1_0.json\n",
      "(3296, 2)\n",
      "packet_json_split/b2_p5_1_0_2.json\n",
      "(3201, 2)\n",
      "packet_json_split/b4_p2_3_0.json\n",
      "(2868, 2)\n",
      "packet_json_split/b5_p3_2_4.json\n",
      "(3017, 2)\n",
      "packet_json_split/b3_p4_2_4.json\n",
      "(3425, 2)\n",
      "packet_json_split/b2_p4_2_0.json\n",
      "(3669, 2)\n",
      "packet_json_split/b5_p4_1_0.json\n",
      "(2546, 2)\n",
      "packet_json_split/b2_p5_1_4.json\n",
      "(3180, 2)\n",
      "packet_json_split/b5_p3_2_1.json\n",
      "(3105, 2)\n",
      "packet_json_split/b2_p3_2_1.json\n",
      "(3432, 2)\n",
      "packet_json_split/b3_p4_1_0_2.json\n",
      "(3139, 2)\n",
      "packet_json_split/b5_p3_3_4.json\n",
      "(3155, 2)\n",
      "packet_json_split/b1_p1_1_0.json\n",
      "(3184, 2)\n",
      "packet_json_split/b4_p5_2_4.json\n",
      "(3144, 2)\n",
      "packet_json_split/b1_p3_2_0.json\n",
      "(2913, 2)\n",
      "packet_json_split/b3_p2_3_1.json\n",
      "(3064, 2)\n",
      "packet_json_split/b3_p1_3_4.json\n",
      "(3452, 2)\n",
      "packet_json_split/b4_p2_1_0_2.json\n",
      "(3306, 2)\n",
      "packet_json_split/b2_p1_1_4.json\n",
      "(3110, 2)\n",
      "packet_json_split/b4_p5_3_0_2.json\n",
      "(3049, 2)\n",
      "packet_json_split/b2_p3_1_1.json\n",
      "(3660, 2)\n",
      "packet_json_split/b5_p5_2_0_2.json\n",
      "(3296, 2)\n",
      "生成了 300 个样本特征\n",
      "第一个样本的特征形状: (3136, 2)\n"
     ]
    }
   ],
   "source": [
    "features_list = []\n",
    "\n",
    "# 遍历每个样本并生成特征\n",
    "\n",
    "\n",
    "       # 将特征添加到列表中\n",
    "\n",
    "# 查看生成的 features_list\n",
    "\n",
    "# count = 0\n",
    "\n",
    "for data_path in data_paths:\n",
    "  # count +=1\n",
    "  print(data_path)\n",
    "  features = process_json(data_path)\n",
    "  features_list.append(features)\n",
    "  # if count >=50: break\n",
    "\n",
    "  print(features.shape)\n",
    "print(f\"生成了 {len(features_list)} 个样本特征\")\n",
    "print(f\"第一个样本的特征形状: {features_list[0].shape}\")\n",
    "#  print(data_path)\n",
    "  #print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cp0Z8KQWLeGr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截断后的特征张量形状: torch.Size([300, 3000, 2])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if split:fixed_time_steps = 3000\n",
    "else: fixed_time_steps = 12000\n",
    "# 截断或补零到固定长度\n",
    "aligned_features = []\n",
    "for feature in features_list:\n",
    "    if feature.shape[0] > fixed_time_steps:\n",
    "        truncated = feature[:fixed_time_steps, :]  # 截断\n",
    "    else:\n",
    "        truncated = np.pad(feature, ((0, fixed_time_steps - feature.shape[0]), (0, 0)), mode='constant')  # 补零\n",
    "    aligned_features.append(truncated)\n",
    "\n",
    "# 转为张量\n",
    "features_tensor =  torch.tensor(np.stack(aligned_features, axis=0),dtype=torch.float32)\n",
    "print(f\"截断后的特征张量形状: {features_tensor.shape}\")\n",
    "print(type(features_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split:\n",
    "    train_dataset=TensorDataset(features_tensor[0:270],labels_tensor[0:270])\n",
    "    eval_dataset =TensorDataset(features_tensor[270:-1],labels_tensor[270:-1])\n",
    "else:\n",
    "    train_dataset=TensorDataset(features_tensor[0:70],labels_tensor[0:70])\n",
    "    eval_dataset =TensorDataset(features_tensor[70:-1],labels_tensor[70:-1])\n",
    "batch_size=16\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "eval_loader  = DataLoader(eval_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2,dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Define an LSTM with multiple layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True,dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time-step's output for classification\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=2\n",
    "hidden_size=64\n",
    "output_size=4\n",
    "num_layers = 1     # number of LSTM layers\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers=num_layers,dropout=0.4)\n",
    "# model.add(Dense(units))\n",
    "\n",
    "# inputs=features_tensor\n",
    "model = model.to(device)\n",
    "# model = model\n",
    "# inputs = inputs.to(device)\n",
    "# labels = labels_tensor\n",
    "torch.cuda.empty_cache()\n",
    "# outputs = model(inputs)\n",
    "\n",
    "# print(f\"outputs:{outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1732663139656,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "weKcuP3nQRP1",
    "outputId": "4d5abf9f-b90b-44ce-b6f5-e9b022b2e453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3905, Train Accuracy: 24.81%\n",
      "Eval Loss: 1.3945, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [2/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3867, Train Accuracy: 25.19%\n",
      "Eval Loss: 1.3931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [3/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3854, Train Accuracy: 27.78%\n",
      "Eval Loss: 1.3972, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [4/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3830, Train Accuracy: 24.81%\n",
      "Eval Loss: 1.3991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [5/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3824, Train Accuracy: 26.30%\n",
      "Eval Loss: 1.4048, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [6/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3799, Train Accuracy: 27.78%\n",
      "Eval Loss: 1.4044, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [7/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.3759, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4282, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [8/10000000], Learning Rate: 0.001\n",
      "Train Loss: 1.4655, Train Accuracy: 28.52%\n",
      "Eval Loss: 1.6818, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [9/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.4367, Train Accuracy: 26.30%\n",
      "Eval Loss: 1.4136, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [10/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.3838, Train Accuracy: 27.78%\n",
      "Eval Loss: 1.3932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [11/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.3858, Train Accuracy: 24.81%\n",
      "Eval Loss: 1.3932, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [12/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.3826, Train Accuracy: 27.04%\n",
      "Eval Loss: 1.3992, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [13/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.3853, Train Accuracy: 25.93%\n",
      "Eval Loss: 1.4051, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [14/10000000], Learning Rate: 0.00095\n",
      "Train Loss: 1.3818, Train Accuracy: 28.52%\n",
      "Eval Loss: 1.4050, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [15/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3793, Train Accuracy: 30.00%\n",
      "Eval Loss: 1.4040, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [16/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3796, Train Accuracy: 28.15%\n",
      "Eval Loss: 1.4076, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [17/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3782, Train Accuracy: 27.04%\n",
      "Eval Loss: 1.4131, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [18/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3767, Train Accuracy: 27.78%\n",
      "Eval Loss: 1.4119, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [19/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3740, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.4087, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [20/10000000], Learning Rate: 0.0009025\n",
      "Train Loss: 1.3729, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.4133, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [21/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3726, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.4178, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [22/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3695, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.4192, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [23/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3674, Train Accuracy: 30.00%\n",
      "Eval Loss: 1.4290, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [24/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3661, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4382, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [25/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3636, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.4424, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [26/10000000], Learning Rate: 0.000857375\n",
      "Train Loss: 1.3635, Train Accuracy: 28.52%\n",
      "Eval Loss: 1.4496, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [27/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3603, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4618, Eval Accuracy--6.90%\n",
      "---------------------------------------------------\n",
      "Epoch [28/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3585, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4704, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [29/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3549, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.4730, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [30/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3555, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5077, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [31/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3539, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.4869, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [32/10000000], Learning Rate: 0.0008145062499999999\n",
      "Train Loss: 1.3551, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.4715, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [33/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3559, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.5002, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [34/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3520, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.4854, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [35/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3516, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.4999, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [36/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3506, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.4956, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [37/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3500, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5011, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [38/10000000], Learning Rate: 0.0007737809374999998\n",
      "Train Loss: 1.3473, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5309, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [39/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3481, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.4887, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [40/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3461, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5044, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [41/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3615, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.4863, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [42/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3532, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.4912, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [43/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3467, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5023, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [44/10000000], Learning Rate: 0.0007350918906249997\n",
      "Train Loss: 1.3446, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5501, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Model saved with Accuracy: Traning--30.74% and Eval--34.48%\n",
      "Epoch [45/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3660, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4180, Eval Accuracy--34.48%\n",
      "---------------------------------------------------\n",
      "Epoch [46/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3672, Train Accuracy: 30.00%\n",
      "Eval Loss: 1.4095, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [47/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3632, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.4078, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [48/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3605, Train Accuracy: 30.00%\n",
      "Eval Loss: 1.4184, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [49/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3573, Train Accuracy: 28.52%\n",
      "Eval Loss: 1.4316, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [50/10000000], Learning Rate: 0.0006983372960937497\n",
      "Train Loss: 1.3553, Train Accuracy: 29.26%\n",
      "Eval Loss: 1.4637, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [51/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3681, Train Accuracy: 27.78%\n",
      "Eval Loss: 1.4351, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [52/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3576, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.4396, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [53/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3534, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.4432, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [54/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3473, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.4424, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [55/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3469, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.4465, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [56/10000000], Learning Rate: 0.0006634204312890621\n",
      "Train Loss: 1.3440, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.4687, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [57/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3415, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.4683, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [58/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3419, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.4811, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [59/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3386, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5139, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [60/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3430, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5026, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [61/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3364, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5088, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [62/10000000], Learning Rate: 0.000630249409724609\n",
      "Train Loss: 1.3360, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5233, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [63/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3343, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5230, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [64/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3320, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5287, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [65/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3346, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5374, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [66/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3323, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5348, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [67/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3283, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5045, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [68/10000000], Learning Rate: 0.0005987369392383785\n",
      "Train Loss: 1.3280, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5591, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [69/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3343, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5304, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [70/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3311, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5237, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [71/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3286, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5310, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [72/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3260, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5346, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [73/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3363, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5155, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [74/10000000], Learning Rate: 0.0005688000922764595\n",
      "Train Loss: 1.3297, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5507, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [75/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3217, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5336, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [76/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3272, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5374, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [77/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3433, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5453, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [78/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3240, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5652, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [79/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3215, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5455, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [80/10000000], Learning Rate: 0.0005403600876626365\n",
      "Train Loss: 1.3230, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5539, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [81/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3159, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.5384, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [82/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3170, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5505, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [83/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3156, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5317, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [84/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3178, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5887, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [85/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3177, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5434, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [86/10000000], Learning Rate: 0.0005133420832795047\n",
      "Train Loss: 1.3263, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5426, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [87/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3102, Train Accuracy: 40.74%\n",
      "Eval Loss: 1.5503, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [88/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3101, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5765, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [89/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3089, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5897, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [90/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3061, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5838, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [91/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3086, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5942, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [92/10000000], Learning Rate: 0.00048767497911552944\n",
      "Train Loss: 1.3225, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5447, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [93/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3129, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5569, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [94/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3077, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5525, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [95/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3045, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.5722, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [96/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3048, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5940, Eval Accuracy--10.34%\n",
      "---------------------------------------------------\n",
      "Epoch [97/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3370, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5862, Eval Accuracy--6.90%\n",
      "---------------------------------------------------\n",
      "Epoch [98/10000000], Learning Rate: 0.00046329123015975297\n",
      "Train Loss: 1.3130, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5413, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [99/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.3009, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.5259, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [100/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.2994, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6004, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [101/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.3044, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5740, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [102/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.2986, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5669, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [103/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.2913, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5960, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [104/10000000], Learning Rate: 0.0004401266686517653\n",
      "Train Loss: 1.3032, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5778, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [105/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.2973, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5597, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [106/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.3020, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5775, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [107/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.3003, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5799, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [108/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.3029, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5682, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [109/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.2919, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5633, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [110/10000000], Learning Rate: 0.00041812033521917703\n",
      "Train Loss: 1.2934, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5900, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [111/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2893, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5902, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [112/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2880, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5756, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [113/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2963, Train Accuracy: 40.74%\n",
      "Eval Loss: 1.6187, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [114/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2894, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5657, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [115/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2839, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5749, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [116/10000000], Learning Rate: 0.00039721431845821814\n",
      "Train Loss: 1.2829, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5824, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [117/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2954, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5965, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [118/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2860, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5199, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [119/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2876, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5675, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [120/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2827, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5863, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [121/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2730, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5857, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [122/10000000], Learning Rate: 0.0003773536025353072\n",
      "Train Loss: 1.2722, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5875, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [123/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.2703, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5865, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [124/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.2745, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.6047, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [125/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.3087, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.6370, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [126/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.3187, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5564, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [127/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.2883, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5706, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [128/10000000], Learning Rate: 0.0003584859224085418\n",
      "Train Loss: 1.2737, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5597, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [129/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.2746, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5505, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [130/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.2713, Train Accuracy: 44.44%\n",
      "Eval Loss: 1.5834, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [131/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.2592, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.7827, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [132/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.4800, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.7836, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [133/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.4271, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.6803, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [134/10000000], Learning Rate: 0.0003405616262881147\n",
      "Train Loss: 1.4041, Train Accuracy: 28.15%\n",
      "Eval Loss: 1.6381, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [135/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3863, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [136/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3760, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.5673, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [137/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3705, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.5754, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [138/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3682, Train Accuracy: 29.63%\n",
      "Eval Loss: 1.5628, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [139/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3672, Train Accuracy: 30.00%\n",
      "Eval Loss: 1.5398, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [140/10000000], Learning Rate: 0.00032353354497370894\n",
      "Train Loss: 1.3639, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.5369, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [141/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3627, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5375, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [142/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3622, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5232, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [143/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3596, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5374, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [144/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3593, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5262, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [145/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3570, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5260, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [146/10000000], Learning Rate: 0.00030735686772502346\n",
      "Train Loss: 1.3566, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5013, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [147/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3560, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5079, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [148/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3542, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5179, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [149/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3547, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5185, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [150/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3533, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5044, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [151/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3530, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5223, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [152/10000000], Learning Rate: 0.00029198902433877225\n",
      "Train Loss: 1.3516, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.4980, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [153/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3522, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.5154, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [154/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3512, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.5120, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [155/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3514, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5071, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [156/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3509, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5082, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [157/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3489, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5119, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [158/10000000], Learning Rate: 0.00027738957312183364\n",
      "Train Loss: 1.3500, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.4998, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [159/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3486, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5113, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [160/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3479, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5043, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [161/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3482, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5011, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [162/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3474, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5123, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [163/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3474, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5079, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [164/10000000], Learning Rate: 0.0002635200944657419\n",
      "Train Loss: 1.3473, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5210, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [165/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3476, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.5199, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [166/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3452, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5074, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [167/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3458, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5187, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [168/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3442, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5101, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [169/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3445, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5107, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [170/10000000], Learning Rate: 0.0002503440897424548\n",
      "Train Loss: 1.3451, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5158, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [171/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3441, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5166, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [172/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3434, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5349, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [173/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3434, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5250, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [174/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3436, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5208, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [175/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3431, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5093, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [176/10000000], Learning Rate: 0.00023782688525533205\n",
      "Train Loss: 1.3426, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5214, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [177/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3425, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5142, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [178/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3420, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5280, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [179/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3424, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5156, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [180/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3413, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5181, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [181/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3408, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5271, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [182/10000000], Learning Rate: 0.00022593554099256544\n",
      "Train Loss: 1.3408, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5282, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [183/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3410, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5309, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [184/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3406, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5175, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [185/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3404, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5320, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [186/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3395, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5348, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [187/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3395, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5373, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [188/10000000], Learning Rate: 0.00021463876394293716\n",
      "Train Loss: 1.3395, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5382, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [189/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3387, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5377, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [190/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3386, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5466, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [191/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3381, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5216, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [192/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3381, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5400, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [193/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3394, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5360, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [194/10000000], Learning Rate: 0.0002039068257457903\n",
      "Train Loss: 1.3380, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5420, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [195/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3367, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5266, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [196/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3366, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.5377, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [197/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3365, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5469, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [198/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3363, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5377, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [199/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3366, Train Accuracy: 31.11%\n",
      "Eval Loss: 1.5391, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [200/10000000], Learning Rate: 0.00019371148445850077\n",
      "Train Loss: 1.3365, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5457, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [201/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3349, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5427, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [202/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3347, Train Accuracy: 30.74%\n",
      "Eval Loss: 1.5464, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [203/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3361, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5584, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [204/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3340, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5577, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [205/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3349, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5597, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [206/10000000], Learning Rate: 0.00018402591023557573\n",
      "Train Loss: 1.3350, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5632, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [207/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3339, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5449, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [208/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3340, Train Accuracy: 31.85%\n",
      "Eval Loss: 1.5541, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [209/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3325, Train Accuracy: 31.48%\n",
      "Eval Loss: 1.5426, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [210/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3325, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5402, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [211/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3325, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5433, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [212/10000000], Learning Rate: 0.00017482461472379692\n",
      "Train Loss: 1.3333, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5520, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [213/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3316, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5407, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [214/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3311, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5562, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [215/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3317, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5590, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [216/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3314, Train Accuracy: 32.22%\n",
      "Eval Loss: 1.5624, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [217/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3300, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5550, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [218/10000000], Learning Rate: 0.00016608338398760707\n",
      "Train Loss: 1.3309, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5517, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [219/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3302, Train Accuracy: 32.59%\n",
      "Eval Loss: 1.5651, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [220/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3293, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5650, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [221/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3312, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5608, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [222/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3292, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5573, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [223/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3286, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5562, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [224/10000000], Learning Rate: 0.0001577792147882267\n",
      "Train Loss: 1.3280, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5580, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [225/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3286, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5514, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [226/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3266, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5571, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [227/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3268, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5635, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [228/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3248, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5472, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [229/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3255, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5674, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [230/10000000], Learning Rate: 0.00014989025404881537\n",
      "Train Loss: 1.3242, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.5706, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [231/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3243, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5505, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [232/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3235, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5807, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [233/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3232, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5696, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [234/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3216, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5661, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [235/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3208, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5687, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [236/10000000], Learning Rate: 0.00014239574134637458\n",
      "Train Loss: 1.3204, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5593, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [237/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3213, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5738, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [238/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3189, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5581, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [239/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3173, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5725, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [240/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3164, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5772, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [241/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3129, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5710, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [242/10000000], Learning Rate: 0.00013527595427905584\n",
      "Train Loss: 1.3120, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5542, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [243/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.3109, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5655, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [244/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.3093, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5668, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [245/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.3077, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5603, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [246/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.3050, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5608, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [247/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.3061, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5708, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [248/10000000], Learning Rate: 0.00012851215656510304\n",
      "Train Loss: 1.2994, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5690, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [249/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.3000, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5566, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [250/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.3009, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5742, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [251/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.3002, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5788, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [252/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.2984, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5663, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [253/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.2932, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5704, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [254/10000000], Learning Rate: 0.00012208654873684788\n",
      "Train Loss: 1.2914, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5491, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [255/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2952, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5545, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [256/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2912, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5679, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [257/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2878, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5602, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [258/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2879, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5422, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [259/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2866, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5699, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [260/10000000], Learning Rate: 0.00011598222130000548\n",
      "Train Loss: 1.2975, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5609, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [261/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2959, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5508, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [262/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2855, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5848, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [263/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2885, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5703, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [264/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2845, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5793, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [265/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2887, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5804, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [266/10000000], Learning Rate: 0.00011018311023500519\n",
      "Train Loss: 1.2897, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5763, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [267/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2858, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5654, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [268/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2882, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5892, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [269/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2844, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5656, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [270/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2802, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5766, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [271/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2753, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5887, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [272/10000000], Learning Rate: 0.00010467395472325493\n",
      "Train Loss: 1.2777, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5976, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [273/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2762, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5744, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [274/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2740, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5753, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [275/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2718, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5545, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [276/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2698, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5687, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [277/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2739, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5651, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [278/10000000], Learning Rate: 9.944025698709218e-05\n",
      "Train Loss: 1.2634, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5427, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [279/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2662, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5486, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [280/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2817, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.5470, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [281/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2773, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5915, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [282/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2683, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5523, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [283/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2575, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5645, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [284/10000000], Learning Rate: 9.446824413773756e-05\n",
      "Train Loss: 1.2627, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.5539, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [285/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2552, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5548, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [286/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2599, Train Accuracy: 43.70%\n",
      "Eval Loss: 1.6007, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [287/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2801, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5423, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [288/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2978, Train Accuracy: 40.74%\n",
      "Eval Loss: 1.6421, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [289/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2745, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5487, Eval Accuracy--31.03%\n",
      "---------------------------------------------------\n",
      "Epoch [290/10000000], Learning Rate: 8.974483193085068e-05\n",
      "Train Loss: 1.2511, Train Accuracy: 43.70%\n",
      "Eval Loss: 1.5300, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [291/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2555, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.5553, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [292/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2543, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.5248, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [293/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2547, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.5861, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [294/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2553, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.6082, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [295/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2564, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.5333, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [296/10000000], Learning Rate: 8.525759033430814e-05\n",
      "Train Loss: 1.2732, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5488, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [297/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2519, Train Accuracy: 43.70%\n",
      "Eval Loss: 1.5647, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [298/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2685, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.5553, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [299/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2499, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5564, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [300/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2473, Train Accuracy: 41.48%\n",
      "Eval Loss: 1.5808, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [301/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2441, Train Accuracy: 41.48%\n",
      "Eval Loss: 1.5333, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [302/10000000], Learning Rate: 8.099471081759274e-05\n",
      "Train Loss: 1.2709, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5904, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [303/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.2968, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5581, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [304/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.3220, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5259, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [305/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.3110, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5642, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [306/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.3012, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5871, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [307/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.2836, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5776, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [308/10000000], Learning Rate: 7.69449752767131e-05\n",
      "Train Loss: 1.2647, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5765, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [309/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2581, Train Accuracy: 40.00%\n",
      "Eval Loss: 1.5892, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [310/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2555, Train Accuracy: 40.74%\n",
      "Eval Loss: 1.6045, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [311/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2515, Train Accuracy: 40.37%\n",
      "Eval Loss: 1.6077, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [312/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2523, Train Accuracy: 40.74%\n",
      "Eval Loss: 1.5978, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [313/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2452, Train Accuracy: 41.48%\n",
      "Eval Loss: 1.5941, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [314/10000000], Learning Rate: 7.309772651287744e-05\n",
      "Train Loss: 1.2487, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.6268, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [315/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2443, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.6085, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [316/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2448, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5985, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [317/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2413, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [318/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2430, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5939, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [319/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2426, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5577, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [320/10000000], Learning Rate: 6.944284018723356e-05\n",
      "Train Loss: 1.2366, Train Accuracy: 41.11%\n",
      "Eval Loss: 1.5933, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [321/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2353, Train Accuracy: 41.48%\n",
      "Eval Loss: 1.5763, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [322/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2317, Train Accuracy: 42.59%\n",
      "Eval Loss: 1.5852, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [323/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2424, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.5987, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [324/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2336, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5735, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [325/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2343, Train Accuracy: 42.59%\n",
      "Eval Loss: 1.5788, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [326/10000000], Learning Rate: 6.597069817787189e-05\n",
      "Train Loss: 1.2323, Train Accuracy: 44.07%\n",
      "Eval Loss: 1.5736, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [327/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2334, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.5976, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [328/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2327, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.5683, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [329/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2262, Train Accuracy: 44.07%\n",
      "Eval Loss: 1.5976, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [330/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2244, Train Accuracy: 43.70%\n",
      "Eval Loss: 1.5582, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [331/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2262, Train Accuracy: 44.81%\n",
      "Eval Loss: 1.5847, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [332/10000000], Learning Rate: 6.267216326897829e-05\n",
      "Train Loss: 1.2250, Train Accuracy: 43.33%\n",
      "Eval Loss: 1.5758, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [333/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2253, Train Accuracy: 44.07%\n",
      "Eval Loss: 1.5787, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [334/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2228, Train Accuracy: 44.44%\n",
      "Eval Loss: 1.6004, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [335/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2221, Train Accuracy: 44.44%\n",
      "Eval Loss: 1.5948, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [336/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2224, Train Accuracy: 44.44%\n",
      "Eval Loss: 1.6298, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [337/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2206, Train Accuracy: 45.19%\n",
      "Eval Loss: 1.6471, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [338/10000000], Learning Rate: 5.953855510552937e-05\n",
      "Train Loss: 1.2178, Train Accuracy: 45.19%\n",
      "Eval Loss: 1.6515, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [339/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2129, Train Accuracy: 44.44%\n",
      "Eval Loss: 1.6469, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [340/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2115, Train Accuracy: 43.70%\n",
      "Eval Loss: 1.6683, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [341/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2182, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.6409, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [342/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2207, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5875, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [343/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2258, Train Accuracy: 42.96%\n",
      "Eval Loss: 1.5772, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [344/10000000], Learning Rate: 5.65616273502529e-05\n",
      "Train Loss: 1.2362, Train Accuracy: 42.22%\n",
      "Eval Loss: 1.6522, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [345/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.2278, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.6808, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [346/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.2233, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.6672, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [347/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.2188, Train Accuracy: 45.19%\n",
      "Eval Loss: 1.6543, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [348/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.2444, Train Accuracy: 41.85%\n",
      "Eval Loss: 1.5528, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [349/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.3599, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5514, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [350/10000000], Learning Rate: 5.373354598274025e-05\n",
      "Train Loss: 1.3549, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.6099, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [351/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3798, Train Accuracy: 34.07%\n",
      "Eval Loss: 1.5922, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [352/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3687, Train Accuracy: 32.96%\n",
      "Eval Loss: 1.6098, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [353/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3560, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5984, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [354/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3602, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.5684, Eval Accuracy--27.59%\n",
      "---------------------------------------------------\n",
      "Epoch [355/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3491, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5573, Eval Accuracy--24.14%\n",
      "---------------------------------------------------\n",
      "Epoch [356/10000000], Learning Rate: 5.104686868360323e-05\n",
      "Train Loss: 1.3414, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5494, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [357/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3181, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5877, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [358/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3144, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5818, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [359/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3088, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6198, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [360/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3070, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5737, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [361/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3018, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5559, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [362/10000000], Learning Rate: 4.849452524942307e-05\n",
      "Train Loss: 1.3066, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5608, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [363/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3044, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5697, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [364/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3046, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5782, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [365/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3121, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5269, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [366/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3118, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5523, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [367/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3151, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5623, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [368/10000000], Learning Rate: 4.606979898695191e-05\n",
      "Train Loss: 1.3097, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5759, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [369/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.3080, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5914, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [370/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.3061, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5630, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [371/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.3042, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5979, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [372/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.3014, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5818, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [373/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.3049, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5465, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [374/10000000], Learning Rate: 4.376630903760431e-05\n",
      "Train Loss: 1.2987, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5973, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [375/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.2985, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5859, Eval Accuracy--20.69%\n",
      "---------------------------------------------------\n",
      "Epoch [376/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.3008, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5751, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [377/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.3021, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5938, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [378/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.3184, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.6095, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [379/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.3211, Train Accuracy: 33.33%\n",
      "Eval Loss: 1.6422, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [380/10000000], Learning Rate: 4.157799358572409e-05\n",
      "Train Loss: 1.3107, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.6150, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [381/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3107, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5977, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [382/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3047, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6025, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [383/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3053, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5946, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [384/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3042, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6089, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [385/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3041, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6051, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [386/10000000], Learning Rate: 3.9499093906437885e-05\n",
      "Train Loss: 1.3052, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5891, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [387/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3032, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5804, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [388/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3014, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5978, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [389/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3011, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5982, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [390/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3002, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.6097, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [391/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3009, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5978, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [392/10000000], Learning Rate: 3.752413921111599e-05\n",
      "Train Loss: 1.3017, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5948, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [393/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.3021, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6007, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [394/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.2976, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.6007, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [395/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.2986, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5839, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [396/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.2978, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5969, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [397/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.3003, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5983, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [398/10000000], Learning Rate: 3.564793225056019e-05\n",
      "Train Loss: 1.3019, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5684, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [399/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2998, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5965, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [400/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2974, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6072, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [401/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2957, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5870, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [402/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2962, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5936, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [403/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2942, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5794, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [404/10000000], Learning Rate: 3.3865535638032174e-05\n",
      "Train Loss: 1.2955, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5849, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [405/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2974, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5812, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [406/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2959, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5816, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [407/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2932, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5843, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [408/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2942, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5853, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [409/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2938, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5854, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [410/10000000], Learning Rate: 3.2172258856130564e-05\n",
      "Train Loss: 1.2955, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5965, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [411/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2963, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6025, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [412/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2978, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5709, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [413/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2924, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6001, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [414/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2929, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.6018, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [415/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2929, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5926, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [416/10000000], Learning Rate: 3.056364591332403e-05\n",
      "Train Loss: 1.2896, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5882, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [417/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2925, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5766, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [418/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2958, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5656, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [419/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2969, Train Accuracy: 34.81%\n",
      "Eval Loss: 1.5736, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [420/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2905, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5877, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [421/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2902, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5880, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [422/10000000], Learning Rate: 2.903546361765783e-05\n",
      "Train Loss: 1.2898, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5815, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [423/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2890, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5825, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [424/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2902, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [425/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2883, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5783, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [426/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2951, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.6071, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [427/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2951, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [428/10000000], Learning Rate: 2.758369043677494e-05\n",
      "Train Loss: 1.2920, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5986, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [429/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2948, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [430/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2922, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5902, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [431/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2920, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [432/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2879, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5830, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [433/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2868, Train Accuracy: 35.56%\n",
      "Eval Loss: 1.5802, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [434/10000000], Learning Rate: 2.620450591493619e-05\n",
      "Train Loss: 1.2863, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5884, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [435/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2857, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5703, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [436/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2839, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5681, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [437/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2847, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5800, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [438/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2863, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5830, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [439/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2856, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6014, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [440/10000000], Learning Rate: 2.489428061918938e-05\n",
      "Train Loss: 1.2836, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5720, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [441/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2835, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5852, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [442/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2853, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [443/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2826, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5869, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [444/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2822, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5837, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [445/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2841, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5843, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [446/10000000], Learning Rate: 2.364956658822991e-05\n",
      "Train Loss: 1.2812, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [447/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2817, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5893, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [448/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2816, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5914, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [449/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2830, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5905, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [450/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2862, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5893, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [451/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2849, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6185, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [452/10000000], Learning Rate: 2.2467088258818413e-05\n",
      "Train Loss: 1.2816, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5835, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [453/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2846, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [454/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2797, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5908, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [455/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2788, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.6031, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [456/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2786, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5892, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [457/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2800, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5871, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [458/10000000], Learning Rate: 2.134373384587749e-05\n",
      "Train Loss: 1.2801, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [459/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2786, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [460/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2796, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5789, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [461/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2791, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6082, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [462/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2783, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [463/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2789, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5990, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [464/10000000], Learning Rate: 2.0276547153583614e-05\n",
      "Train Loss: 1.2796, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.5625, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [465/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2772, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5898, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [466/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2771, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5841, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [467/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2777, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6068, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [468/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2769, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6038, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [469/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2812, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.5712, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [470/10000000], Learning Rate: 1.9262719795904432e-05\n",
      "Train Loss: 1.2811, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6005, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [471/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2757, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5812, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [472/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2774, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [473/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2763, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6106, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [474/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2783, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5940, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [475/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2754, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6180, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [476/10000000], Learning Rate: 1.829958380610921e-05\n",
      "Train Loss: 1.2914, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [477/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2864, Train Accuracy: 36.30%\n",
      "Eval Loss: 1.6055, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [478/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2835, Train Accuracy: 35.93%\n",
      "Eval Loss: 1.6002, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [479/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2772, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6147, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [480/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2763, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6064, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [481/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2753, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6080, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [482/10000000], Learning Rate: 1.738460461580375e-05\n",
      "Train Loss: 1.2757, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5864, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [483/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2783, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.5939, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [484/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2760, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6074, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [485/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2752, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6002, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [486/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2742, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5971, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [487/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2866, Train Accuracy: 35.19%\n",
      "Eval Loss: 1.5794, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [488/10000000], Learning Rate: 1.6515374385013564e-05\n",
      "Train Loss: 1.2991, Train Accuracy: 33.70%\n",
      "Eval Loss: 1.5955, Eval Accuracy--17.24%\n",
      "---------------------------------------------------\n",
      "Epoch [489/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2894, Train Accuracy: 34.44%\n",
      "Eval Loss: 1.5811, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [490/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2827, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6076, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [491/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2752, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6253, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [492/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2772, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6158, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [493/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2751, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6120, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [494/10000000], Learning Rate: 1.5689605665762886e-05\n",
      "Train Loss: 1.2736, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6103, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [495/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2744, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [496/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2740, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [497/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2751, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5971, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [498/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2750, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5966, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [499/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2726, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6132, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [500/10000000], Learning Rate: 1.490512538247474e-05\n",
      "Train Loss: 1.2730, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6156, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [501/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2725, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6101, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [502/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2716, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6034, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [503/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2737, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6121, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [504/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2724, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [505/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2709, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6114, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [506/10000000], Learning Rate: 1.4159869113351003e-05\n",
      "Train Loss: 1.2720, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6195, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [507/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2715, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5965, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [508/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2707, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5964, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [509/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2699, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [510/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2697, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6050, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [511/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2713, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [512/10000000], Learning Rate: 1.3451875657683452e-05\n",
      "Train Loss: 1.2725, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6022, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [513/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2696, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5911, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [514/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2692, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6038, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [515/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2690, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5941, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [516/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2675, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [517/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2696, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6117, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [518/10000000], Learning Rate: 1.277928187479928e-05\n",
      "Train Loss: 1.2693, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6083, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [519/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2678, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6008, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [520/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2692, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5897, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [521/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2675, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6046, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [522/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2662, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5958, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [523/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2670, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6035, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [524/10000000], Learning Rate: 1.2140317781059316e-05\n",
      "Train Loss: 1.2674, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5996, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [525/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2673, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6066, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [526/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2689, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6145, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [527/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2659, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5889, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [528/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2675, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [529/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2700, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6057, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [530/10000000], Learning Rate: 1.153330189200635e-05\n",
      "Train Loss: 1.2669, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6053, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [531/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2729, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6117, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [532/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2720, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5904, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [533/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2666, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [534/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2669, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5990, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [535/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2661, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5997, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [536/10000000], Learning Rate: 1.0956636797406032e-05\n",
      "Train Loss: 1.2657, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6170, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [537/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2668, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6063, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [538/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2683, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6012, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [539/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2695, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5818, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [540/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2670, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6091, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [541/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2688, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6223, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [542/10000000], Learning Rate: 1.0408804957535729e-05\n",
      "Train Loss: 1.2664, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6034, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [543/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2654, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6080, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [544/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2668, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5942, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [545/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2669, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6044, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [546/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2680, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6089, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [547/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2672, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6025, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [548/10000000], Learning Rate: 9.888364709658941e-06\n",
      "Train Loss: 1.2664, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6116, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [549/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2663, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.6138, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [550/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2666, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.6177, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [551/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2689, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6057, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [552/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2654, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6246, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [553/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2635, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6336, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [554/10000000], Learning Rate: 9.393946474175994e-06\n",
      "Train Loss: 1.2641, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5944, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [555/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2642, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6177, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [556/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2650, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6006, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [557/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2648, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6133, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [558/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2655, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5971, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [559/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2656, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6090, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [560/10000000], Learning Rate: 8.924249150467194e-06\n",
      "Train Loss: 1.2644, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6191, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [561/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2648, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5957, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [562/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2642, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6099, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [563/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2637, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5851, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [564/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2653, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [565/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2625, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6069, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [566/10000000], Learning Rate: 8.478036692943835e-06\n",
      "Train Loss: 1.2641, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6121, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [567/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2649, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6249, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [568/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2632, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5993, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [569/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2665, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6075, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [570/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2692, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [571/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2755, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6076, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [572/10000000], Learning Rate: 8.054134858296643e-06\n",
      "Train Loss: 1.2716, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.6099, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [573/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2648, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6086, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [574/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2677, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [575/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2671, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6183, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [576/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2629, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6158, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [577/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2637, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6121, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [578/10000000], Learning Rate: 7.65142811538181e-06\n",
      "Train Loss: 1.2625, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6169, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [579/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2632, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6003, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [580/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2627, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6100, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [581/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2629, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6086, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [582/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2630, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [583/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2611, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6129, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [584/10000000], Learning Rate: 7.26885670961272e-06\n",
      "Train Loss: 1.2661, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6115, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [585/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2630, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6079, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [586/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2640, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5879, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [587/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2629, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6135, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [588/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2617, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6217, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [589/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2624, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6123, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [590/10000000], Learning Rate: 6.905413874132084e-06\n",
      "Train Loss: 1.2609, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5891, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [591/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2625, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6000, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [592/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2619, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [593/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2636, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6081, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [594/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2633, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6017, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [595/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2615, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [596/10000000], Learning Rate: 6.5601431804254795e-06\n",
      "Train Loss: 1.2618, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6041, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [597/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2637, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5959, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [598/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2621, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6161, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [599/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6223, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [600/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2624, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6000, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [601/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2617, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6070, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [602/10000000], Learning Rate: 6.232136021404205e-06\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6208, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [603/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [604/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2624, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [605/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2606, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [606/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5866, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [607/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [608/10000000], Learning Rate: 5.920529220333994e-06\n",
      "Train Loss: 1.2615, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [609/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2627, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5987, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [610/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6270, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [611/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5993, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [612/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6017, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [613/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2603, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6060, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [614/10000000], Learning Rate: 5.624502759317295e-06\n",
      "Train Loss: 1.2607, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6000, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [615/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2587, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6143, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [616/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2597, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6082, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [617/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2607, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [618/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2610, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6047, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [619/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2597, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6219, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [620/10000000], Learning Rate: 5.34327762135143e-06\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6017, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [621/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2590, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5912, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [622/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2590, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6134, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [623/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2591, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [624/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2590, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5930, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [625/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6030, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [626/10000000], Learning Rate: 5.076113740283858e-06\n",
      "Train Loss: 1.2608, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5900, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [627/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2599, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6144, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [628/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2579, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5988, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [629/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2589, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6067, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [630/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2598, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5915, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [631/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2588, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6009, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [632/10000000], Learning Rate: 4.8223080532696655e-06\n",
      "Train Loss: 1.2586, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6009, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [633/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2592, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5904, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [634/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2580, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6003, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [635/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2577, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5868, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [636/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2587, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5896, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [637/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2613, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6161, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [638/10000000], Learning Rate: 4.581192650606182e-06\n",
      "Train Loss: 1.2653, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6053, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [639/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2604, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6172, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [640/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6146, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [641/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2585, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5861, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [642/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2580, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6033, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [643/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2584, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6214, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [644/10000000], Learning Rate: 4.3521330180758725e-06\n",
      "Train Loss: 1.2577, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6059, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [645/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5939, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [646/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2594, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5992, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [647/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2564, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6158, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [648/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2583, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5966, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [649/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2571, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5966, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [650/10000000], Learning Rate: 4.1345263671720786e-06\n",
      "Train Loss: 1.2581, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [651/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2564, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [652/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2568, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5915, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [653/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2584, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6138, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [654/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2574, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6274, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [655/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2576, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [656/10000000], Learning Rate: 3.927800048813474e-06\n",
      "Train Loss: 1.2585, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6173, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [657/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2572, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [658/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2571, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [659/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2569, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5966, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [660/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2566, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6023, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [661/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2568, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6096, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [662/10000000], Learning Rate: 3.7314100463728006e-06\n",
      "Train Loss: 1.2569, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [663/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2568, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5990, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [664/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2565, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6054, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [665/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2562, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5936, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [666/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2567, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [667/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2561, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [668/10000000], Learning Rate: 3.5448395440541604e-06\n",
      "Train Loss: 1.2559, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5903, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [669/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2561, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5898, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [670/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2571, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6234, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [671/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2556, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.5864, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [672/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2555, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6165, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [673/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2550, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [674/10000000], Learning Rate: 3.3675975668514524e-06\n",
      "Train Loss: 1.2567, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6167, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [675/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2559, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6093, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [676/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2556, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [677/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2564, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6094, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [678/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2560, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6100, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [679/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2558, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [680/10000000], Learning Rate: 3.1992176885088796e-06\n",
      "Train Loss: 1.2568, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6000, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [681/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2547, Train Accuracy: 39.63%\n",
      "Eval Loss: 1.6131, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [682/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2557, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6131, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [683/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2557, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.6172, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [684/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2544, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6094, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [685/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2562, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6169, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [686/10000000], Learning Rate: 3.0392568040834356e-06\n",
      "Train Loss: 1.2555, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5877, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [687/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2561, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5782, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [688/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2543, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6097, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [689/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2556, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5983, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [690/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2550, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6058, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [691/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2533, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5960, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [692/10000000], Learning Rate: 2.8872939638792635e-06\n",
      "Train Loss: 1.2543, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [693/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2542, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5984, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [694/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2544, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6171, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [695/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2550, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [696/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2565, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [697/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2555, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6174, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [698/10000000], Learning Rate: 2.7429292656853003e-06\n",
      "Train Loss: 1.2561, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5846, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [699/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2552, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6240, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [700/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2546, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6175, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [701/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2538, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5981, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [702/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2541, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6186, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [703/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2535, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6007, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [704/10000000], Learning Rate: 2.605782802401035e-06\n",
      "Train Loss: 1.2551, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6274, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [705/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6162, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [706/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2712, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [707/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5927, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [708/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2669, Train Accuracy: 39.26%\n",
      "Eval Loss: 1.5996, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [709/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2757, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5861, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [710/10000000], Learning Rate: 2.475493662280983e-06\n",
      "Train Loss: 1.2744, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5838, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [711/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2749, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6102, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [712/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2737, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [713/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2740, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [714/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2724, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [715/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2726, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5895, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [716/10000000], Learning Rate: 2.351718979166934e-06\n",
      "Train Loss: 1.2742, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [717/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2734, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5857, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [718/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2731, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5874, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [719/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2754, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6093, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [720/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2804, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [721/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2779, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6014, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [722/10000000], Learning Rate: 2.234133030208587e-06\n",
      "Train Loss: 1.2728, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6069, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [723/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2715, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5874, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [724/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2714, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6014, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [725/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2703, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5876, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [726/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2703, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5995, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [727/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2704, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5786, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [728/10000000], Learning Rate: 2.1224263786981576e-06\n",
      "Train Loss: 1.2695, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5926, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [729/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2698, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5909, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [730/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2707, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [731/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2714, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5875, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [732/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2701, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5835, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [733/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2698, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6054, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [734/10000000], Learning Rate: 2.0163050597632494e-06\n",
      "Train Loss: 1.2689, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5840, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [735/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2700, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5810, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [736/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2707, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5983, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [737/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2689, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5941, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [738/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2706, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6085, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [739/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2711, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5832, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [740/10000000], Learning Rate: 1.915489806775087e-06\n",
      "Train Loss: 1.2739, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [741/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2714, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5925, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [742/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2707, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [743/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2700, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6072, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [744/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2704, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [745/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2700, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5814, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [746/10000000], Learning Rate: 1.8197153164363325e-06\n",
      "Train Loss: 1.2695, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5984, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [747/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2699, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6108, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [748/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2697, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6143, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [749/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2691, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5981, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [750/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2687, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [751/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2685, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5914, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [752/10000000], Learning Rate: 1.7287295506145157e-06\n",
      "Train Loss: 1.2702, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5713, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [753/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2697, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5859, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [754/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2707, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5890, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [755/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2698, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6029, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [756/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2698, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [757/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2694, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5960, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [758/10000000], Learning Rate: 1.6422930730837899e-06\n",
      "Train Loss: 1.2782, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5764, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [759/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2817, Train Accuracy: 36.67%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [760/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2777, Train Accuracy: 37.04%\n",
      "Eval Loss: 1.6024, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [761/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2763, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5900, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [762/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2707, Train Accuracy: 37.41%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [763/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2704, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5914, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [764/10000000], Learning Rate: 1.5601784194296004e-06\n",
      "Train Loss: 1.2688, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [765/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2708, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6047, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [766/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2689, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [767/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2700, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5716, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [768/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2694, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5950, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [769/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2693, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5888, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [770/10000000], Learning Rate: 1.4821694984581202e-06\n",
      "Train Loss: 1.2702, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [771/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2700, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5795, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [772/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2695, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5763, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [773/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2698, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [774/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2680, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [775/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2677, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6080, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [776/10000000], Learning Rate: 1.4080610235352142e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5826, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [777/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2695, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6004, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [778/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6135, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [779/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5941, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [780/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5909, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [781/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2676, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5802, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [782/10000000], Learning Rate: 1.3376579723584535e-06\n",
      "Train Loss: 1.2676, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5891, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [783/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2681, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5941, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [784/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2664, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6113, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [785/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2695, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5868, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [786/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2657, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6063, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [787/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2673, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5877, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [788/10000000], Learning Rate: 1.2707750737405307e-06\n",
      "Train Loss: 1.2673, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5996, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [789/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2670, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [790/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2677, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6140, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [791/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2665, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [792/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2671, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6060, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [793/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2676, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5837, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [794/10000000], Learning Rate: 1.2072363200535042e-06\n",
      "Train Loss: 1.2666, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5908, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [795/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2683, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5812, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [796/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2683, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5918, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [797/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2670, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5997, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [798/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2670, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5803, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [799/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2666, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [800/10000000], Learning Rate: 1.146874504050829e-06\n",
      "Train Loss: 1.2657, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5907, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [801/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2663, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5950, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [802/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2658, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6009, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [803/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2668, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6004, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [804/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2656, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [805/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2658, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [806/10000000], Learning Rate: 1.0895307788482876e-06\n",
      "Train Loss: 1.2669, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5889, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [807/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2653, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6035, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [808/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2660, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5874, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [809/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2664, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6135, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [810/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2661, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [811/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2675, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [812/10000000], Learning Rate: 1.0350542399058731e-06\n",
      "Train Loss: 1.2652, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5993, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [813/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5826, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [814/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2646, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [815/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2660, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6062, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [816/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2652, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5926, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [817/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2647, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6047, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [818/10000000], Learning Rate: 9.833015279105794e-07\n",
      "Train Loss: 1.2661, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5905, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [819/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5794, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [820/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2645, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6014, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [821/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2649, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5869, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [822/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2664, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5953, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [823/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2657, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [824/10000000], Learning Rate: 9.341364515150503e-07\n",
      "Train Loss: 1.2648, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5891, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [825/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2652, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6036, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [826/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2664, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6027, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [827/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2655, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [828/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2646, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6074, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [829/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2649, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [830/10000000], Learning Rate: 8.874296289392978e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5894, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [831/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5781, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [832/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5797, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [833/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5789, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [834/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [835/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [836/10000000], Learning Rate: 8.430581474923329e-07\n",
      "Train Loss: 1.2645, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5972, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [837/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5796, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [838/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [839/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2659, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6066, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [840/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2654, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [841/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2665, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [842/10000000], Learning Rate: 8.009052401177162e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5921, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [843/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2662, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [844/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2641, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [845/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2659, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6006, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [846/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5854, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [847/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5965, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [848/10000000], Learning Rate: 7.608599781118303e-07\n",
      "Train Loss: 1.2660, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6102, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [849/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5874, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [850/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2655, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [851/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2649, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5815, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [852/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [853/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2655, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [854/10000000], Learning Rate: 7.228169792062388e-07\n",
      "Train Loss: 1.2648, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6102, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [855/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2662, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [856/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2649, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6093, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [857/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5981, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [858/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2659, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6004, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [859/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [860/10000000], Learning Rate: 6.866761302459269e-07\n",
      "Train Loss: 1.2651, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6033, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [861/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [862/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2656, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5842, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [863/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5930, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [864/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6052, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [865/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [866/10000000], Learning Rate: 6.523423237336305e-07\n",
      "Train Loss: 1.2641, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [867/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6183, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [868/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [869/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6146, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [870/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5800, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [871/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6043, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [872/10000000], Learning Rate: 6.197252075469489e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [873/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 37.78%\n",
      "Eval Loss: 1.6085, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [874/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2642, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5863, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [875/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5912, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [876/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2644, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6013, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [877/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [878/10000000], Learning Rate: 5.887389471696014e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6130, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [879/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5985, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [880/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5921, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [881/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6152, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [882/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2646, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [883/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [884/10000000], Learning Rate: 5.593019998111213e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [885/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6058, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [886/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2649, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [887/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [888/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5948, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [889/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5922, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [890/10000000], Learning Rate: 5.313368998205652e-07\n",
      "Train Loss: 1.2647, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [891/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5848, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [892/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2660, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5785, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [893/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5867, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [894/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2650, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5939, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [895/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6045, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [896/10000000], Learning Rate: 5.047700548295369e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6173, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [897/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [898/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6045, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [899/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6037, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [900/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5888, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [901/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [902/10000000], Learning Rate: 4.7953155208806e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5937, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [903/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6054, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [904/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6103, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [905/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [906/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2642, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [907/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5986, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [908/10000000], Learning Rate: 4.55554974483657e-07\n",
      "Train Loss: 1.2642, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6068, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [909/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6036, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [910/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [911/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5889, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [912/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2645, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5956, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [913/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6021, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [914/10000000], Learning Rate: 4.327772257594741e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [915/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2653, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5848, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [916/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6125, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [917/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5935, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [918/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2641, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6096, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [919/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5889, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [920/10000000], Learning Rate: 4.111383644715004e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5963, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [921/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6076, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [922/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [923/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6015, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [924/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6022, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [925/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5829, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [926/10000000], Learning Rate: 3.905814462479254e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5916, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [927/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5799, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [928/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5898, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [929/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6064, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [930/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5981, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [931/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [932/10000000], Learning Rate: 3.710523739355291e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6211, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [933/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [934/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6087, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [935/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6021, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [936/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6041, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [937/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [938/10000000], Learning Rate: 3.524997552387526e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5996, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [939/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6143, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [940/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5956, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [941/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [942/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [943/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5879, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [944/10000000], Learning Rate: 3.34874767476815e-07\n",
      "Train Loss: 1.2633, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [945/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5756, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [946/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2656, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6011, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [947/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [948/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6061, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [949/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6016, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [950/10000000], Learning Rate: 3.181310291029742e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5983, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [951/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [952/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6134, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [953/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [954/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [955/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5842, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [956/10000000], Learning Rate: 3.0222447764782547e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6034, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [957/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [958/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5971, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [959/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [960/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6043, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [961/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [962/10000000], Learning Rate: 2.8711325376543416e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5935, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [963/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5976, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [964/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6033, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [965/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5905, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [966/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5865, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [967/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5866, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [968/10000000], Learning Rate: 2.7275759107716244e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6008, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [969/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5903, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [970/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5965, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [971/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2648, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5824, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [972/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5994, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [973/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5872, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [974/10000000], Learning Rate: 2.591197115233043e-07\n",
      "Train Loss: 1.2633, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [975/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5857, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [976/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6174, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [977/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5821, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [978/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6048, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [979/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [980/10000000], Learning Rate: 2.4616372594713905e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5864, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [981/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6124, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [982/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6084, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [983/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5776, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [984/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5906, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [985/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5954, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [986/10000000], Learning Rate: 2.3385553964978208e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5891, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [987/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2630, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6125, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [988/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5948, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [989/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6012, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [990/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6085, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [991/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2633, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6071, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [992/10000000], Learning Rate: 2.2216276266729297e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6132, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [993/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5985, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [994/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5909, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [995/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [996/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6048, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [997/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6117, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [998/10000000], Learning Rate: 2.110546245339283e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [999/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5896, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1000/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5896, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1001/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2636, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1002/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5804, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1003/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1004/10000000], Learning Rate: 2.0050189330723186e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6127, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1005/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5918, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1006/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6007, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1007/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5885, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1008/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5919, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1009/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2643, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6112, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1010/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5829, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1011/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5977, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1012/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6133, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1013/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1014/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5958, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1015/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5798, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1016/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1017/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2647, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6028, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1018/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6011, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1019/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2646, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6201, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1020/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2635, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6133, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1021/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5658, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1022/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1023/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1024/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1025/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6023, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1026/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5885, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1027/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6066, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1028/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1029/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5992, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1030/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1031/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6171, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1032/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1033/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5924, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1034/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6116, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1035/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1036/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1037/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6194, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1038/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6190, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1039/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6087, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1040/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5803, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1041/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5992, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1042/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5995, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1043/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6026, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1044/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6054, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1045/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1046/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6129, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1047/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5874, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1048/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5894, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1049/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6003, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1050/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6124, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1051/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6002, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1052/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5863, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1053/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5959, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1054/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2638, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6116, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1055/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1056/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1057/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1058/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2628, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5884, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1059/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5984, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1060/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2640, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6082, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1061/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6095, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1062/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6022, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1063/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1064/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1065/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1066/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1067/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5842, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1068/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5918, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1069/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5971, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1070/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1071/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6028, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1072/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1073/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2630, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5854, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1074/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2639, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5950, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1075/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5892, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1076/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6083, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1077/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6157, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1078/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5834, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1079/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5976, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1080/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2629, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6050, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1081/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1082/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1083/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6006, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1084/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5915, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1085/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6027, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1086/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1087/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6067, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1088/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5887, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1089/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5793, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1090/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5794, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1091/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5889, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1092/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1093/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2632, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5983, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1094/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6179, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1095/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6012, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1096/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5976, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1097/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6106, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1098/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5891, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1099/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1100/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6065, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1101/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5811, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1102/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5936, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1103/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5936, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1104/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1105/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1106/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6066, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1107/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1108/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2633, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5919, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1109/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6071, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1110/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1111/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2630, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5951, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1112/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5884, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1113/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1114/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1115/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5893, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1116/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5911, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1117/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1118/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2634, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5898, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1119/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5854, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1120/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2626, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5760, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1121/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1122/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5847, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1123/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6177, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1124/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5907, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1125/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1126/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6121, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1127/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1128/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5811, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1129/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5964, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1130/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1131/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1132/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5814, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1133/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6083, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1134/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5994, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1135/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6119, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1136/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5923, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1137/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5864, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1138/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5925, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1139/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5929, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1140/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1141/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1142/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1143/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1144/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5985, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1145/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1146/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5953, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1147/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5937, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1148/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1149/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6135, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1150/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6007, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1151/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1152/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1153/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5892, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1154/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5950, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1155/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5822, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1156/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5927, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1157/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1158/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5890, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1159/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6105, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1160/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2622, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6231, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1161/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5845, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1162/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2631, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1163/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5990, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1164/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6136, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1165/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5806, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1166/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6089, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1167/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6015, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1168/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5930, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1169/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2627, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1170/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1171/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6036, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1172/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1173/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5967, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1174/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5979, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1175/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5829, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1176/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5937, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1177/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1178/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5959, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1179/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6086, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1180/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5846, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1181/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1182/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6060, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1183/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6115, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1184/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1185/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5898, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1186/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6048, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1187/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1188/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6066, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1189/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1190/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6032, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1191/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1192/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5973, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1193/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1194/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6009, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1195/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6015, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1196/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5828, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1197/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6188, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1198/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5951, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1199/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6045, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1200/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5799, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1201/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1202/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6038, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1203/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5851, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1204/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1205/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6017, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1206/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1207/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5754, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1208/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5852, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1209/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1210/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6191, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1211/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2619, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5957, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1212/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2623, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1213/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1214/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6024, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1215/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5994, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1216/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5958, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1217/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5995, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1218/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5890, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1219/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5895, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1220/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6174, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1221/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5803, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1222/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6074, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1223/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5774, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1224/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2637, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5990, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1225/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2625, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6023, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1226/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2624, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6143, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1227/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6031, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1228/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6007, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1229/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5925, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1230/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6172, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1231/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5831, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1232/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5930, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1233/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6084, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1234/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6113, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1235/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5957, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1236/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5892, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1237/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6235, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1238/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1239/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1240/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1241/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5959, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1242/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1243/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5809, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1244/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5817, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1245/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1246/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6148, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1247/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5943, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1248/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1249/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6070, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1250/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1251/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6041, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1252/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5896, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1253/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6068, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1254/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1255/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5836, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1256/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5919, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1257/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5829, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1258/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6137, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1259/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6074, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1260/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1261/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6084, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1262/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.5835, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1263/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5776, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1264/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5904, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1265/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5913, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1266/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1267/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5919, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1268/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6004, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1269/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5858, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1270/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5988, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1271/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1272/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5958, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1273/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6009, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1274/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1275/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1276/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5914, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1277/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5877, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1278/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6032, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1279/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1280/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5783, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1281/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5866, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1282/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6044, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1283/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5963, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1284/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5976, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1285/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6021, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1286/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5936, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1287/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1288/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1289/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5942, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1290/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5914, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1291/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5927, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1292/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2613, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6175, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1293/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5826, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1294/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5867, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1295/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5806, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1296/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5942, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1297/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1298/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5940, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1299/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5799, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1300/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5911, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1301/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1302/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5987, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1303/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5960, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1304/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6131, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1305/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5987, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1306/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1307/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6090, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1308/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6067, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1309/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5839, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1310/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5851, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1311/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5917, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1312/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5818, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1313/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1314/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5983, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1315/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5844, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1316/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2616, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6023, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1317/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1318/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2617, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1319/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6011, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1320/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5991, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1321/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1322/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5940, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1323/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5879, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1324/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6142, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1325/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5834, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1326/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5869, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1327/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6169, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1328/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5998, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1329/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1330/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2618, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5818, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1331/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1332/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5894, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1333/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5984, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1334/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1335/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5840, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1336/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1337/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5855, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1338/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6076, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1339/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5901, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1340/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5895, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1341/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5880, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1342/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5744, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1343/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5992, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1344/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1345/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2621, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6109, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1346/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1347/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5910, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1348/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5839, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1349/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6113, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1350/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2609, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5841, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1351/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5955, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1352/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5946, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1353/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2620, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6067, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1354/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2603, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1355/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6043, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1356/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1357/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6135, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1358/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1359/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5925, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1360/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5987, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1361/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6007, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1362/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1363/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5952, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1364/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6025, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1365/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6008, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1366/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2607, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5930, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1367/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5819, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1368/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5956, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1369/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6055, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1370/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6124, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1371/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1372/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5920, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1373/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5890, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1374/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6035, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1375/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6142, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1376/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6063, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1377/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5907, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1378/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1379/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2614, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5862, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1380/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1381/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5948, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1382/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1383/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5962, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1384/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5935, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1385/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1386/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5958, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1387/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6022, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1388/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1389/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5747, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1390/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6027, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1391/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6002, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1392/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5861, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1393/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5868, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1394/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5916, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1395/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5959, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1396/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6089, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1397/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6036, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1398/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5957, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1399/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5960, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1400/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2612, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1401/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5905, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1402/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6035, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1403/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1404/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6073, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1405/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6037, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1406/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5881, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1407/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5964, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1408/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1409/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1410/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5920, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1411/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5903, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1412/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5918, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1413/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5764, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1414/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2580, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1415/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6030, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1416/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5859, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1417/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5964, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1418/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5765, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1419/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1420/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1421/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6140, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1422/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5762, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1423/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5860, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1424/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5903, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1425/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5953, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1426/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2606, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6092, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1427/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5879, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1428/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6039, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1429/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2611, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5897, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1430/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5813, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1431/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5801, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1432/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6100, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1433/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6083, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1434/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6143, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1435/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2615, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5999, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1436/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1437/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6013, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1438/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1439/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5870, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1440/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5933, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1441/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5948, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1442/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5926, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1443/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5884, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1444/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2586, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6094, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1445/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6067, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1446/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1447/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2608, Train Accuracy: 38.15%\n",
      "Eval Loss: 1.6053, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1448/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1449/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.52%\n",
      "Eval Loss: 1.6062, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1450/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5798, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1451/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1452/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5869, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1453/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1454/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5965, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1455/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2605, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5839, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1456/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2610, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6102, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1457/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1458/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5975, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1459/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1460/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5828, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1461/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5882, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1462/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1463/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1464/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6049, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1465/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5901, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1466/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6008, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1467/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5951, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1468/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5944, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1469/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5901, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1470/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5857, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1471/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5730, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1472/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1473/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5883, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1474/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5917, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1475/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6097, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1476/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5774, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1477/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1478/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5894, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1479/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6125, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1480/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5953, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1481/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6055, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1482/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2598, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1483/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1484/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5937, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1485/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1486/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2586, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5942, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1487/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2604, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5989, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1488/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6150, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1489/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6016, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1490/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1491/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1492/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6006, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1493/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5935, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1494/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6038, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1495/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1496/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5855, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1497/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6096, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1498/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6071, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1499/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5899, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1500/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6043, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1501/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6082, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1502/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6078, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1503/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5774, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1504/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1505/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2597, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5900, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1506/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5758, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1507/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5970, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1508/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6030, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1509/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5785, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1510/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1511/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5893, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1512/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5915, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1513/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1514/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6097, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1515/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5908, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1516/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5929, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1517/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5835, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1518/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6030, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1519/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1520/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2586, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5906, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1521/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6087, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1522/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5937, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1523/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6019, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1524/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5919, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1525/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2571, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1526/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6037, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1527/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5964, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1528/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6180, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1529/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2599, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1530/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2567, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6025, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1531/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5894, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1532/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6082, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1533/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6006, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1534/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2578, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6110, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1535/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5802, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1536/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6065, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1537/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2602, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5873, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1538/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5969, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1539/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5961, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1540/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5968, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1541/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6025, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1542/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6100, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1543/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5945, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1544/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5939, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1545/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6078, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1546/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6016, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1547/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5912, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1548/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2596, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5825, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1549/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6111, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1550/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6114, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1551/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5925, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1552/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5942, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1553/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6020, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1554/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2576, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5834, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1555/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2601, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5938, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1556/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5771, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1557/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6107, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1558/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2572, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5895, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1559/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2583, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5978, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1560/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5901, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1561/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6015, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1562/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2578, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5775, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1563/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5749, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1564/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6116, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1565/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5795, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1566/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6004, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1567/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5981, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1568/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6050, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1569/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2594, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6008, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1570/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5863, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1571/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6029, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1572/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5803, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1573/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2573, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5878, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1574/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5845, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1575/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2578, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1576/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5980, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1577/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5985, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1578/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6052, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1579/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2591, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6151, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1580/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6057, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1581/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2575, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5867, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1582/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1583/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2575, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6170, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1584/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6034, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1585/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2580, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6181, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1586/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2576, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5879, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1587/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5833, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1588/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2574, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1589/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2588, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5917, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1590/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2582, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5963, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1591/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1592/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5977, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1593/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2585, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5859, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1594/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2589, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6058, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1595/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2574, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6076, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1596/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5997, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1597/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2600, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5947, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1598/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2566, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5870, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1599/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6029, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1600/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2586, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5840, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1601/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5966, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1602/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5932, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1603/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5976, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1604/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2584, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5982, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1605/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5928, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1606/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2567, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6014, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1607/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2572, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5993, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1608/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2593, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6058, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1609/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2574, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5798, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1610/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2578, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5827, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1611/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6016, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1612/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2575, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5939, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1613/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2567, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6035, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1614/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2569, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5912, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1615/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2571, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5934, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1616/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2562, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5931, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1617/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2581, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6045, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1618/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5974, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1619/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2574, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6111, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1620/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2590, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5949, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1621/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2587, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6018, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1622/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2574, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5906, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1623/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2569, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5811, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1624/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5922, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1625/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2577, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6105, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1626/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2579, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5886, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1627/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2595, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6010, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1628/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2571, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.5902, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n",
      "Epoch [1629/10000000], Learning Rate: 1.9047679864187027e-07\n",
      "Train Loss: 1.2592, Train Accuracy: 38.89%\n",
      "Eval Loss: 1.6001, Eval Accuracy--13.79%\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# 清除梯度\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 更新权重\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 累计损失\u001b[39;00m\n\u001b[1;32m     33\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/optim/adam.py:506\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m--> 506\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_div_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     denom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_add(exp_avg_sq_sqrt, eps)\n\u001b[1;32m    509\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom, step_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 分类任务使用交叉熵损失\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # Decay learning rate every 10 epochs\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)  # Decrease LR by 5% every epoch\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.95,patience=5)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/lstm_training')  # This will store logs in 'runs/lstm_training'\n",
    "\n",
    "# 6. 训练循环\n",
    "num_epochs = 10000000  # 训练轮次\n",
    "max_accu=0.25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    total_loss = 0  # 累计损失\n",
    "    correct_preds = 0  # 记录正确预测的数量\n",
    "    total_preds = 0  # 总的预测数\n",
    "   \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # 前向传播\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)  # 获取模型输出\n",
    "        loss = criterion(outputs, targets)  # 计算损失\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权重\n",
    "        \n",
    "        # 累计损失\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 计算正确预测的数量\n",
    "        _, predicted = torch.max(outputs, 1)  # 获取预测类别\n",
    "        correct_preds += (predicted == targets).sum().item()  # 统计正确的数量\n",
    "        total_preds += targets.size(0)  # 统计总的预测数\n",
    "    \n",
    "    # 计算训练损失和准确率\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct_preds / total_preds\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "   \n",
    "\n",
    "      # Log loss to TensorBoard after each epoch\n",
    "    writer.add_scalar('Loss/train', total_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar('Learning Rate', current_lr, epoch)\n",
    "\n",
    "    total_loss=0\n",
    "    correct_preds = 0  # Reset for evaluation\n",
    "    total_preds = 0  # Reset for evaluation\n",
    "\n",
    "    # 7. 评估模型（可选）\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 在评估时不计算梯度\n",
    "        for batch_idx, (inputs, targets) in enumerate(eval_loader):\n",
    "            # 前向传播\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)  # 获取模型输出\n",
    "            loss = criterion(outputs, targets)  # 计算损失\n",
    "            \n",
    "            # 累计损失\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 计算正确预测的数量\n",
    "            _, predicted = torch.max(outputs, 1)  # 获取预测类别\n",
    "            correct_preds += (predicted == targets).sum().item()  # 统计正确的数量\n",
    "            total_preds += targets.size(0)  # 统计总的预测数\n",
    "        # 计算eval损失和准确率\n",
    "    eval_loss = total_loss / len(eval_loader)\n",
    "    eval_accuracy = correct_preds / total_preds\n",
    "    scheduler.step(eval_loss)\n",
    "    # scheduler.step()\n",
    "    if eval_accuracy > max_accu:\n",
    "        max_accu = max(eval_accuracy,max_accu)  # Update max accuracy\n",
    "        model_filename = f\"model_epoch_{epoch+1}tran_acc_{train_accuracy*100:.2f}% val_acc_{eval_accuracy*100:.2f}%.pth\"\n",
    "        torch.save(model.state_dict(), model_filename)  # Save model to disko disk\n",
    "        print(f\"Model saved with Accuracy: Traning--{train_accuracy*100:.2f}% and Eval--{eval_accuracy*100:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Learning Rate: {current_lr}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%\")\n",
    "    print(f\"Eval Loss: {eval_loss:.4f}, Eval Accuracy--{eval_accuracy*100:.2f}%\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    writer.add_scalars('Loss',{'Train':train_loss,'Eval':eval_loss} , epoch)\n",
    "    writer.add_scalars('Accuracy',{'Train':train_accuracy,'Eval':eval_accuracy} , epoch)\n",
    "\n",
    "writer.close\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    test_preds = []  # To store predictions\n",
    "    test_labels = []  # To store true labels\n",
    "    \n",
    "    # Loop through the train_loader (or test_loader if you're evaluating the test set)\n",
    "    for inputs, targets in train_loader:\n",
    "        # Move inputs and targets to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Ensure the input shape is (batch_size, seq_len, input_size) for LSTM\n",
    "        # Adjust this depending on the actual input shape\n",
    "        # inputs = inputs.view(inputs.size(0), -1, inputs.size(1))  # Assuming inputs have shape (batch_size, input_size)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get predictions by taking the argmax along the output dimension\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Store predictions and true labels as NumPy arrays\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Print predictions and labels for debugging (optional)\n",
    "    print(\"Predictions: \", test_preds)\n",
    "    print(\"True Labels: \", test_labels)\n",
    "\n",
    "    # You may want to calculate accuracy or other metrics after the loop\n",
    "    # For example, calculate accuracy:\n",
    "    accuracy = sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n",
    "    # print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "    # accuracy = accuracy_score(test_labels, test_preds)\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 8189,
     "status": "error",
     "timestamp": 1732684520771,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "X_WFfnPiC3D6",
    "outputId": "71b1210e-2f45-4ff2-fcf8-b392e9d468ef"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "\n",
    "# # Define folder paths\n",
    "# input_folder_path = \"202_packet_json\"  # Input folder containing original JSON files\n",
    "# output_folder_path = \"202_packet_json_10\"  # New folder to save filtered files\n",
    "\n",
    "# # Ensure the output folder exists\n",
    "# os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# # Iterate over files in the input folder\n",
    "# for filename in os.listdir(input_folder_path):\n",
    "#     # Full file path\n",
    "#     input_file_path = os.path.join(input_folder_path, filename)\n",
    "    \n",
    "#     # Check if it is a JSON file\n",
    "#     if filename.endswith(\".json\"):\n",
    "#         # Open and read the original JSON file\n",
    "#         with open(input_file_path, \"r\") as file:\n",
    "#             data = json.load(file)\n",
    "        \n",
    "#         # Check if '_source' and 'layers' are present in the structure\n",
    "#         if \"_source\" in data and \"layers\" in data[\"_source\"]:\n",
    "#             # Check if \"frame\" is a list of packets\n",
    "#             frames = data[\"_source\"][\"layers\"].get(\"frame\", [])\n",
    "            \n",
    "#             # List to store filtered packets\n",
    "#             filtered_packets = []\n",
    "\n",
    "#             # Extract packets and filter by time range (10s to 20s)\n",
    "#             for packet in frames:\n",
    "#                 # Ensure 'frame.time_relative' exists in each packet\n",
    "#                 if \"frame.time_relative\" in packet:\n",
    "#                     timestamp = float(packet[\"frame.time_relative\"])\n",
    "                    \n",
    "#                     # Filter packets in the time range from 10s to 20s\n",
    "#                     if 10 <= timestamp <= 20:\n",
    "#                         filtered_packets.append(packet)\n",
    "\n",
    "#             # If we have filtered packets, write them to a new file\n",
    "#             if filtered_packets:\n",
    "#                 # Output file path (same name but in the output folder)\n",
    "#                 output_file_path = os.path.join(output_folder_path, filename)\n",
    "                \n",
    "#                 # Write the filtered packets into a new JSON file\n",
    "#                 with open(output_file_path, \"w\") as output_file:\n",
    "#                     json.dump(filtered_packets, output_file, indent=4)\n",
    "\n",
    "#                 print(f\"Processed {filename}, saved to {output_file_path}\")\n",
    "#             else:\n",
    "#                 print(f\"No packets found between 10s and 20s in {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzl3bUNmd9ZerCBXO4n8MF",
   "mount_file_id": "1ppJfjr3KpPki2l-wT2cLvqRXCFUyovZK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "202_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
