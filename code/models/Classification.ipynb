{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# 标签映射\n",
    "label_mapping = {\n",
    "    \"0\": 0,             # static\n",
    "    \"0_2\": 1,           # slightly_move\n",
    "    \"1\": 2,             # move\n",
    "    \"4\": 3              # intensely_move\n",
    "}\n",
    "\n",
    "# 提取文件名对应标签\n",
    "# def get_label_from_filename(filename):\n",
    "#     match = re.search(r'_(\\d+_?\\d*)\\.json$', filename)\n",
    "#     if match:\n",
    "#         label_key = match.group(1)\n",
    "#         return label_mapping.get(label_key, -1)\n",
    "#     return -1\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    return label_mapping.get(filename[8:-5],-1)\n",
    "\n",
    "# 获取文件夹中的文件及其标签\n",
    "def load_files_and_labels(folder_path):\n",
    "    file_list = []\n",
    "    labels = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".json\"):\n",
    "            label = get_label_from_filename(file)\n",
    "            if label != -1:\n",
    "                file_list.append(os.path.join(folder_path, file))\n",
    "                labels.append(label)\n",
    "    return file_list, labels\n",
    "\n",
    "# JSON 文件处理函数\n",
    "def process_json(file_path):\n",
    "    \"\"\"\n",
    "    处理 JSON 文件，提取时间戳和包长度\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            datas = json.load(file)\n",
    "\n",
    "        initial_timestamp = None\n",
    "        for data in datas:\n",
    "            try:\n",
    "                timestamp = float(data[\"_source\"][\"layers\"][\"frame\"][\"frame.time_relative\"])\n",
    "                packet_length = int(data[\"_source\"][\"layers\"][\"frame\"][\"frame.len\"])\n",
    "\n",
    "                if initial_timestamp is None:\n",
    "                    initial_timestamp = timestamp\n",
    "                relative_timestamp = timestamp - initial_timestamp\n",
    "\n",
    "                features.append([relative_timestamp, packet_length])\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "\n",
    "        if features:\n",
    "            features = np.array(features, dtype=float)\n",
    "            features[:, 1] /= 1512  # 归一化包长度\n",
    "        else:\n",
    "            features = np.zeros((1, 2))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        features = np.zeros((1, 2))\n",
    "    return features\n",
    "\n",
    "# 自定义数据集\n",
    "class JsonDataset(Dataset):\n",
    "    def __init__(self, data_paths, labels):\n",
    "        self.data_paths = data_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = process_json(self.data_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(features, dtype=torch.float32), label\n",
    "\n",
    "# 自定义批处理函数\n",
    "def collate_fn(batch):\n",
    "    features, labels = zip(*batch)\n",
    "    features = [torch.tensor(f, dtype=torch.float32) for f in features]\n",
    "    features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return features_padded, labels\n",
    "\n",
    "# 模型定义\n",
    "class TrafficClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TrafficClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4)  # 4分类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, input_dim = x.shape\n",
    "        x = x.reshape(-1, input_dim)\n",
    "        x = self.fc(x)\n",
    "        return x.view(batch_size, sequence_length, -1)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, epochs=10):\n",
    "    model.train()  # 设置为训练模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            output = model(features)  # 模型输出 [batch_size, sequence_length, num_classes]\n",
    "            output = output.reshape(-1, output.shape[-1])  # 展平成 [batch_size * sequence_length, num_classes]\n",
    "            labels = labels.unsqueeze(1).expand(-1, features.shape[1]).reshape(-1)  # [batch_size * sequence_length]\n",
    "\n",
    "            # 损失计算\n",
    "            loss = cross_entropy(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 计算准确率\n",
    "            predictions = torch.argmax(output, dim=1)  # 获取预测类别\n",
    "            correct += (predictions == labels).sum().item()  # 累加正确预测的数量\n",
    "            total += labels.size(0)  # 总样本数\n",
    "\n",
    "        accuracy = correct / total  # 正确率\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.2%}\")\n",
    "        evaluate_model(model,test_loader)\n",
    "\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            output = model(features)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "\n",
    "            labels = labels.unsqueeze(1).expand(-1, features.shape[1]).reshape(-1)\n",
    "\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"Accuracy: {correct / total:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5812/3738001464.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = [torch.tensor(f, dtype=torch.float32) for f in features]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 223.8584, Accuracy: 22.74%\n",
      "Accuracy: 22.85%\n",
      "Epoch 2/100, Loss: 222.5400, Accuracy: 23.50%\n",
      "Accuracy: 22.42%\n",
      "Epoch 3/100, Loss: 222.5366, Accuracy: 25.43%\n",
      "Accuracy: 24.71%\n",
      "Epoch 4/100, Loss: 222.6161, Accuracy: 24.81%\n",
      "Accuracy: 22.38%\n",
      "Epoch 5/100, Loss: 222.2779, Accuracy: 25.26%\n",
      "Accuracy: 23.18%\n",
      "Epoch 6/100, Loss: 222.4100, Accuracy: 25.10%\n",
      "Accuracy: 25.39%\n",
      "Epoch 7/100, Loss: 222.2173, Accuracy: 25.63%\n",
      "Accuracy: 25.31%\n",
      "Epoch 8/100, Loss: 222.3719, Accuracy: 24.68%\n",
      "Accuracy: 24.21%\n",
      "Epoch 9/100, Loss: 222.2204, Accuracy: 23.62%\n",
      "Accuracy: 21.57%\n",
      "Epoch 10/100, Loss: 222.1739, Accuracy: 24.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f6eeccd9e20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nesl/anaconda3/envs/202_proj/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.97%\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"/home/nesl/202_project_hxy_cbl/202_packet_json_new_800\"  # 替换为实际路径\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 加载数据\n",
    "    data_paths, labels = load_files_and_labels(folder_path)\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        data_paths, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 数据加载\n",
    "    train_dataset = JsonDataset(train_paths, train_labels)\n",
    "    test_dataset = JsonDataset(test_paths, test_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # 模型初始化\n",
    "    input_dim = 2\n",
    "    model = TrafficClassifier(input_dim).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 模型训练与评估\n",
    "    train_model(model, train_loader,test_loader, optimizer, epochs=100)\n",
    "    evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "202_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
