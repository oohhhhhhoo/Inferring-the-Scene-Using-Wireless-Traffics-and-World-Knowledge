{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19332,
     "status": "ok",
     "timestamp": 1732687090378,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "y2HfIn_mP2Pd",
    "outputId": "daf85896-d337-4ff7-9725-4bae00f96f88"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732687090379,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "iYzznQU9QRE5"
   },
   "outputs": [],
   "source": [
    "def split_get_label_from_filename(filename):\n",
    "    return label_mapping.get(filename[8:-5],-1)\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    match = re.search(r'_(\\d+_?\\d*)\\.json$', filename)\n",
    "    print(match)\n",
    "    if match:\n",
    "        label_key = match.group(1)\n",
    "        return label_mapping.get(label_key, -1)  # 如果标签不匹配返回 -1\n",
    "\n",
    "# 获取文件夹中的文件及其标签\n",
    "def load_files_and_labels(folder_path,split=False):\n",
    "    file_list = []\n",
    "    labels = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        # print(\"file: \", file)\n",
    "        if file.endswith(\".json\"):\n",
    "            if split:\n",
    "                label = split_get_label_from_filename(file)\n",
    "            else: label = get_label_from_filename(file)\n",
    "            if label != -1:\n",
    "                file_list.append(os.path.join(folder_path, file))\n",
    "                labels.append(label)\n",
    "            #print(f\"File: {file}, Label: {label}\")\n",
    "\n",
    "    return file_list, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732687090379,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "wI5Wdf6hUjU5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. 提取字符并编码为整数索引\n",
    "def hex_to_sequence(hex_feature):\n",
    "    \"\"\"\n",
    "    将十六进制字符串转换为整数索引序列。\n",
    "    去掉冒号并转换为字符对应的索引。\n",
    "    \"\"\"\n",
    "    hex_chars = hex_feature.replace(\":\", \"\")\n",
    "    char_to_index = {char: idx for idx, char in enumerate(\"0123456789abcdef\")}\n",
    "    return [char_to_index[char] for char in hex_chars]\n",
    "\n",
    "def process_json(file_path):\n",
    "    \"\"\"\n",
    "    处理 JSON 文件，提取时间戳、包长度和 raw data 特征，并对特征进行归一化。\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    try:\n",
    "        # 打开 JSON 文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            datas = json.load(file)\n",
    "\n",
    "        # 遍历 JSON 数据，提取时间戳和包长度\n",
    "        initial_timestamp = None\n",
    "        for data in datas:\n",
    "            try:\n",
    "                timestamp = float(data[\"_source\"][\"layers\"][\"frame\"][\"frame.time_relative\"])  # 时间戳\n",
    "                packet_length = int(data[\"_source\"][\"layers\"][\"frame\"][\"frame.len\"])  # 包长度\n",
    "\n",
    "                # 获取数据部分，若不存在则为0\n",
    "                if 'data' in data[\"_source\"][\"layers\"]:\n",
    "                    rawdata = data[\"_source\"][\"layers\"][\"data\"][\"data.data\"]\n",
    "                else:\n",
    "                    rawdata = '0'\n",
    "\n",
    "                # 将原始数据转换为整数序列\n",
    "                data_feature = hex_to_sequence(rawdata)\n",
    "\n",
    "                # 将数据填充或截断为指定长度 2832\n",
    "                if len(data_feature) < 2832:  # 如果长度小于 2832，填充 0\n",
    "                    data_feature += [0] * (2832 - len(data_feature))\n",
    "                elif len(data_feature) > 2832:  # 如果长度大于 2832，截断\n",
    "                    data_feature = data_feature[:2832]\n",
    "\n",
    "                # 如果数据长度不符合预期，打印出来\n",
    "                if len(data_feature) != 2832:\n",
    "                    print(f\"Data feature length mismatch: {len(data_feature)}\")\n",
    "\n",
    "                # 初始化时间戳\n",
    "                if initial_timestamp is None:\n",
    "                    initial_timestamp = timestamp  # 设置初始时间戳\n",
    "\n",
    "                # 计算相对时间戳\n",
    "                relative_timestamp = timestamp - initial_timestamp\n",
    "                # print(type(relative_timestamp))\n",
    "\n",
    "\n",
    "                timestamp_array = np.array([relative_timestamp], dtype=float)\n",
    "                packet_length_array = np.array([packet_length], dtype=float)/1512\n",
    "                data_feature = np.array(data_feature, dtype=float)/15\n",
    "           \n",
    "                # 将特征按顺序组合为 [时间戳, 包长度, 数据特征]\n",
    "                feature = np.hstack((timestamp_array, packet_length_array,data_feature))\n",
    "                \n",
    "                # 添加到特征列表\n",
    "                features.append(feature)\n",
    "\n",
    "            except (KeyError, ValueError) as e:\n",
    "                # 跳过有问题的数据包\n",
    "                print(f\"Skipping packet due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        features_array=np.array(features)\n",
    "        max_timestamp = np.max(features_array[:, 0])  # 获取最大时间戳\n",
    "        # print(\"max\")\n",
    "        features_array[:, 0] = [feature[0] / max_timestamp for feature in features_array]  # 时间戳归一化\n",
    "        # print(\"11\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(Exception)\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        features_array = np.zeros((1, 2834))  # 返回空特征以避免程序中断\n",
    "\n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8859,
     "status": "ok",
     "timestamp": 1732687099233,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "83tjWmfqUzL0",
    "outputId": "60024a7d-b91a-4d51-bda7-85425e4749c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.05026455 0.         ... 0.         0.         0.        ]\n",
      "Feature shape: (11134, 2834)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"202_packet_json/b1_p1_0_2.json\"\n",
    "features = process_json(file_path)\n",
    "#print(features)\n",
    "print(features[0])\n",
    "\n",
    "print(f\"Feature shape: {features.shape}\")\n",
    "# print(f\"Feature type: {type(features)}\")\n",
    "# print(features[:][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1732687099234,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "Z2EwyTe2QRM7",
    "outputId": "aceeb311-cc3d-492e-b05f-c940c6421672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 14), match='_0_2.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<re.Match object; span=(5, 12), match='_0.json'>\n",
      "<re.Match object; span=(5, 12), match='_1.json'>\n",
      "<re.Match object; span=(5, 12), match='_4.json'>\n",
      "<class 'list'>\n",
      "(100,)\n",
      "[1 2 2 2 3 3 3 2 1 1 1 3 2 2 0 0 2 1 3 0 3 3 3 2 0 1 0 2 0 3 0 2 0 0 2 1 2\n",
      " 3 0 1 1 2 1 3 0 2 2 1 1 3 3 3 3 2 2 2 3 1 0 0 0 0 3 0 0 0 3 1 3 1 3 2 1 1\n",
      " 1 3 2 2 0 2 1 0 1 1 1 1 0 2 2 1 0 3 3 0 1 0 3 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 定义文件夹路径 /content/drive/MyDrive/202_project/202_packet_json\n",
    "\n",
    "split = False\n",
    "# folder_path = \"packet_json_split\"\n",
    "if split:\n",
    "    folder_path = \"packet_json_split\" \n",
    "else:\n",
    "    folder_path = \"202_packet_json_new\"\n",
    "\n",
    "# folder_path = \"202_packet_json_new\"  #\n",
    "# 定义标签映射\n",
    "label_mapping = {\n",
    "    \"0\": 0,             # static\n",
    "    \"0_2\": 1,           # slightly_move\n",
    "    \"1\": 2,             # move\n",
    "    \"4\": 3              # intensely_move\n",
    "}\n",
    "\n",
    "# 调用函数获取文件和标签\n",
    "data_paths, labels = load_files_and_labels(folder_path,split)\n",
    "# 用于存储每个样本的特征\n",
    "\n",
    "print(type(labels))\n",
    "labels_array=np.array(labels)#[:50]\n",
    "print(labels_array.shape)\n",
    "print(labels_array)\n",
    "labels_tensor=torch.tensor(labels_array,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOHv4juYLBvy",
    "outputId": "251914c5-78b3-4e69-a9a1-cebaf2fc923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202_packet_json_new/b3_p5_0_2.json\n",
      "(13948, 2834)\n",
      "202_packet_json_new/b1_p5_1.json\n",
      "(11166, 2834)\n",
      "202_packet_json_new/b4_p4_1.json\n",
      "(12725, 2834)\n",
      "202_packet_json_new/b3_p1_1.json\n",
      "(13638, 2834)\n",
      "202_packet_json_new/b1_p1_4.json\n",
      "(12107, 2834)\n",
      "202_packet_json_new/b1_p3_4.json\n",
      "(11231, 2834)\n",
      "202_packet_json_new/b3_p1_4.json\n",
      "(13053, 2834)\n",
      "202_packet_json_new/b5_p1_1.json\n",
      "(12979, 2834)\n",
      "202_packet_json_new/b5_p1_0_2.json\n",
      "(12855, 2834)\n",
      "202_packet_json_new/b2_p1_0_2.json\n",
      "(13799, 2834)\n",
      "202_packet_json_new/b4_p3_0_2.json\n",
      "(12835, 2834)\n",
      "202_packet_json_new/b4_p1_4.json\n",
      "(13320, 2834)\n",
      "202_packet_json_new/b3_p3_1.json\n",
      "(13068, 2834)\n",
      "202_packet_json_new/b1_p2_1.json\n",
      "(10835, 2834)\n",
      "202_packet_json_new/b2_p4_0.json\n",
      "(14132, 2834)\n",
      "202_packet_json_new/b1_p3_0.json\n",
      "(11783, 2834)\n",
      "202_packet_json_new/b2_p4_1.json\n",
      "(13414, 2834)\n",
      "202_packet_json_new/b5_p3_0_2.json\n",
      "(12195, 2834)\n",
      "202_packet_json_new/b4_p5_4.json\n",
      "(12929, 2834)\n",
      "202_packet_json_new/b5_p3_0.json\n",
      "(12413, 2834)\n",
      "202_packet_json_new/b3_p4_4.json\n",
      "(12968, 2834)\n",
      "202_packet_json_new/b3_p3_4.json\n",
      "(13385, 2834)\n",
      "202_packet_json_new/b1_p4_4.json\n",
      "(11252, 2834)\n",
      "202_packet_json_new/b3_p5_1.json\n",
      "(12460, 2834)\n",
      "202_packet_json_new/b4_p3_0.json\n",
      "(13301, 2834)\n",
      "202_packet_json_new/b2_p4_0_2.json\n",
      "(13504, 2834)\n",
      "202_packet_json_new/b2_p5_0.json\n",
      "(13422, 2834)\n",
      "202_packet_json_new/b5_p4_1.json\n",
      "(13459, 2834)\n",
      "202_packet_json_new/b3_p1_0.json\n",
      "(13495, 2834)\n",
      "202_packet_json_new/b3_p5_4.json\n",
      "(11679, 2834)\n",
      "202_packet_json_new/b2_p3_0.json\n",
      "(13197, 2834)\n",
      "202_packet_json_new/b3_p2_1.json\n",
      "(12200, 2834)\n",
      "202_packet_json_new/b4_p4_0.json\n",
      "(12996, 2834)\n",
      "202_packet_json_new/b5_p4_0.json\n",
      "(12834, 2834)\n",
      "202_packet_json_new/b5_p3_1.json\n",
      "(13049, 2834)\n",
      "202_packet_json_new/b1_p3_0_2.json\n",
      "(12291, 2834)\n",
      "202_packet_json_new/b2_p3_1.json\n",
      "(13036, 2834)\n",
      "202_packet_json_new/b5_p1_4.json\n",
      "(13125, 2834)\n",
      "202_packet_json_new/b4_p5_0.json\n",
      "(13003, 2834)\n",
      "202_packet_json_new/b4_p4_0_2.json\n",
      "(12652, 2834)\n",
      "202_packet_json_new/b3_p2_0_2.json\n",
      "(12802, 2834)\n",
      "202_packet_json_new/b4_p5_1.json\n",
      "(13019, 2834)\n",
      "202_packet_json_new/b5_p5_0_2.json\n",
      "(13914, 2834)\n",
      "202_packet_json_new/b2_p1_4.json\n",
      "(12748, 2834)\n",
      "202_packet_json_new/b3_p3_0.json\n",
      "(13197, 2834)\n",
      "202_packet_json_new/b2_p5_1.json\n",
      "(14367, 2834)\n",
      "202_packet_json_new/b4_p2_1.json\n",
      "(12103, 2834)\n",
      "202_packet_json_new/b5_p2_0_2.json\n",
      "(12317, 2834)\n",
      "202_packet_json_new/b1_p2_0_2.json\n",
      "(11703, 2834)\n",
      "202_packet_json_new/b2_p3_4.json\n",
      "(13750, 2834)\n",
      "202_packet_json_new/b3_p2_4.json\n",
      "(13463, 2834)\n",
      "202_packet_json_new/b5_p2_4.json\n",
      "(13586, 2834)\n",
      "202_packet_json_new/b4_p2_4.json\n",
      "(13408, 2834)\n",
      "202_packet_json_new/b1_p4_1.json\n",
      "(11250, 2834)\n",
      "202_packet_json_new/b5_p2_1.json\n",
      "(11409, 2834)\n",
      "202_packet_json_new/b3_p4_1.json\n",
      "(13434, 2834)\n",
      "202_packet_json_new/b2_p4_4.json\n",
      "(13257, 2834)\n",
      "202_packet_json_new/b3_p3_0_2.json\n",
      "(14155, 2834)\n",
      "202_packet_json_new/b5_p5_0.json\n",
      "(12983, 2834)\n",
      "202_packet_json_new/b1_p4_0.json\n",
      "(11898, 2834)\n",
      "202_packet_json_new/b3_p2_0.json\n",
      "(13654, 2834)\n",
      "202_packet_json_new/b5_p2_0.json\n",
      "(12883, 2834)\n",
      "202_packet_json_new/b1_p2_4.json\n",
      "(11484, 2834)\n",
      "202_packet_json_new/b1_p2_0.json\n",
      "(11506, 2834)\n",
      "202_packet_json_new/b2_p2_0.json\n",
      "(13674, 2834)\n",
      "202_packet_json_new/b5_p1_0.json\n",
      "(12067, 2834)\n",
      "202_packet_json_new/b4_p3_4.json\n",
      "(12849, 2834)\n",
      "202_packet_json_new/b2_p2_0_2.json\n",
      "(12974, 2834)\n",
      "202_packet_json_new/b5_p3_4.json\n",
      "(12318, 2834)\n",
      "202_packet_json_new/b2_p3_0_2.json\n",
      "(13395, 2834)\n",
      "202_packet_json_new/b4_p4_4.json\n",
      "(12803, 2834)\n",
      "202_packet_json_new/b5_p5_1.json\n",
      "(13191, 2834)\n",
      "202_packet_json_new/b3_p4_0_2.json\n",
      "(12899, 2834)\n",
      "202_packet_json_new/b5_p4_0_2.json\n",
      "(12060, 2834)\n",
      "202_packet_json_new/b3_p1_0_2.json\n",
      "(13836, 2834)\n",
      "202_packet_json_new/b2_p2_4.json\n",
      "(14391, 2834)\n",
      "202_packet_json_new/b1_p3_1.json\n",
      "(10514, 2834)\n",
      "202_packet_json_new/b4_p1_1.json\n",
      "(13343, 2834)\n",
      "202_packet_json_new/b3_p4_0.json\n",
      "(13755, 2834)\n",
      "202_packet_json_new/b4_p3_1.json\n",
      "(13102, 2834)\n",
      "202_packet_json_new/b2_p5_0_2.json\n",
      "(12880, 2834)\n",
      "202_packet_json_new/b1_p1_0.json\n",
      "(12396, 2834)\n",
      "202_packet_json_new/b4_p1_0_2.json\n",
      "(12623, 2834)\n",
      "202_packet_json_new/b4_p2_0_2.json\n",
      "(13387, 2834)\n",
      "202_packet_json_new/b4_p5_0_2.json\n",
      "(12265, 2834)\n",
      "202_packet_json_new/b1_p5_0_2.json\n",
      "(12397, 2834)\n",
      "202_packet_json_new/b4_p1_0.json\n",
      "(12979, 2834)\n",
      "202_packet_json_new/b2_p2_1.json\n",
      "(13666, 2834)\n",
      "202_packet_json_new/b1_p1_1.json\n",
      "(11836, 2834)\n",
      "202_packet_json_new/b1_p4_0_2.json\n",
      "(11522, 2834)\n",
      "202_packet_json_new/b4_p2_0.json\n",
      "(12065, 2834)\n",
      "202_packet_json_new/b1_p5_4.json\n",
      "(12210, 2834)\n",
      "202_packet_json_new/b2_p5_4.json\n",
      "(13040, 2834)\n",
      "202_packet_json_new/b1_p5_0.json\n",
      "(12206, 2834)\n",
      "202_packet_json_new/b1_p1_0_2.json\n",
      "(12903, 2834)\n",
      "202_packet_json_new/b3_p5_0.json\n",
      "(14334, 2834)\n",
      "202_packet_json_new/b5_p4_4.json\n",
      "(13138, 2834)\n",
      "202_packet_json_new/b2_p1_0.json\n",
      "(11687, 2834)\n",
      "202_packet_json_new/b2_p1_1.json\n",
      "(14576, 2834)\n",
      "202_packet_json_new/b5_p5_4.json\n",
      "(12491, 2834)\n",
      "生成了 100 个样本特征\n",
      "第一个样本的特征形状: (13948, 2834)\n"
     ]
    }
   ],
   "source": [
    "features_list = []\n",
    "\n",
    "# 遍历每个样本并生成特征\n",
    "\n",
    "\n",
    "       # 将特征添加到列表中\n",
    "\n",
    "# 查看生成的 features_list\n",
    "\n",
    "# count = 0\n",
    "\n",
    "for data_path in data_paths:\n",
    "  # count +=1\n",
    "  print(data_path)\n",
    "  features = process_json(data_path)\n",
    "  features_list.append(features)\n",
    "  # if count >=50: break\n",
    "\n",
    "  print(features.shape)\n",
    "print(f\"生成了 {len(features_list)} 个样本特征\")\n",
    "print(f\"第一个样本的特征形状: {features_list[0].shape}\")\n",
    "#  print(data_path)\n",
    "  #print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cp0Z8KQWLeGr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截断后的特征张量形状: torch.Size([100, 12000, 2834])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if split:fixed_time_steps = 3000\n",
    "else: fixed_time_steps = 12000\n",
    "\n",
    "# 截断或补零到固定长度\n",
    "aligned_features = []\n",
    "for feature in features_list:\n",
    "    if feature.shape[0] > fixed_time_steps:\n",
    "        truncated = feature[:fixed_time_steps, :]  # 截断\n",
    "    else:\n",
    "        truncated = np.pad(feature, ((0, fixed_time_steps - feature.shape[0]), (0, 0)), mode='constant')  # 补零\n",
    "    aligned_features.append(truncated)\n",
    "\n",
    "# 转为张量\n",
    "features_tensor =  torch.tensor(np.stack(aligned_features, axis=0),dtype=torch.float32)\n",
    "print(f\"截断后的特征张量形状: {features_tensor.shape}\")\n",
    "print(type(features_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split:\n",
    "    train_dataset=TensorDataset(features_tensor[0:210],labels_tensor[0:210])\n",
    "    eval_dataset =TensorDataset(features_tensor[210:-1],labels_tensor[210:-1])\n",
    "else:\n",
    "    train_dataset=TensorDataset(features_tensor[0:70],labels_tensor[0:70])\n",
    "    eval_dataset =TensorDataset(features_tensor[70:-1],labels_tensor[70:-1])\n",
    "batch_size=16\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "eval_loader  = DataLoader(eval_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# dataset=TensorDataset(features_tensor,labels_tensor)\n",
    "# batch_size=4\n",
    "# train_loader = DataLoader(dataset,batch_size=batch_size,shuffle=False)\n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2,dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Define an LSTM with multiple layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True,dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time-step's output for classification\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=259\n",
    "hidden_size=16\n",
    "output_size=4\n",
    "num_layers = 1     # number of LSTM layers\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers=num_layers,dropout=0)\n",
    "\n",
    "# inputs=features_tensor\n",
    "\n",
    "model.load_state_dict(torch.load(\"LSTM_PCA2_256_hidden16_lr0.001_model_epoch_14tran_acc_78.57% val_acc_48.28%.pth\"))\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "# model = model\n",
    "# inputs = inputs.to(device)\n",
    "# labels = labels_tensor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# outputs = model(inputs)\n",
    "\n",
    "# print(f\"outputs:{outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1732663139656,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "weKcuP3nQRP1",
    "outputId": "4d5abf9f-b90b-44ce-b6f5-e9b022b2e453"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 259, got 2834",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 33\u001b[0m\n\u001b[1;32m     26\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Ensure the input shape is (batch_size, seq_len, input_size) for LSTM\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Adjust this depending on the actual input shape\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# inputs = inputs.view(inputs.size(0), -1, inputs.size(1))  # Assuming inputs have shape (batch_size, input_size)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Get predictions by taking the argmax along the output dimension\u001b[39;00m\n\u001b[1;32m     36\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Forward pass through LSTM\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Use the last time-step's output for classification\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/nn/modules/rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/nn/modules/rnn.py:730\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    729\u001b[0m                        ):\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    732\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    734\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/202_proj/lib/python3.9/site-packages/torch/nn/modules/rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    216\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 259, got 2834"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 分类任务使用交叉熵损失\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # Decay learning rate every 10 epochs\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)  # Decrease LR by 5% every epoch\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.95,patience=5)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/lstm_training')  # This will store logs in 'runs/lstm_training'\n",
    "\n",
    "# 6. 训练循环\n",
    "num_epochs = 5  # 训练轮次\n",
    "max_accu=0.25\n",
    "\n",
    "model.eval()\n",
    "num=0\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    test_preds = []  # To store predictions\n",
    "    test_labels = []  # To store true labels\n",
    "    \n",
    "    # Loop through the train_loader (or test_loader if you're evaluating the test set)\n",
    "    for inputs, targets in train_loader:\n",
    "        # Move inputs and targets to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Ensure the input shape is (batch_size, seq_len, input_size) for LSTM\n",
    "        # Adjust this depending on the actual input shape\n",
    "        # inputs = inputs.view(inputs.size(0), -1, inputs.size(1))  # Assuming inputs have shape (batch_size, input_size)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get predictions by taking the argmax along the output dimension\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        num+=1\n",
    "        \n",
    "        # Store predictions and true labels as NumPy arrays\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Print predictions and labels for debugging (optional)\n",
    "    print(\"Predictions: \", test_preds)\n",
    "    print(\"True Labels: \", test_labels)\n",
    "\n",
    "    # You may want to calculate accuracy or other metrics after the loop\n",
    "    # For example, calculate accuracy:\n",
    "\n",
    "    accuracy = sum(np.array(test_preds) == np.array(test_labels)) / len(test_labels)\n",
    "    # print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    diff_indices = [i for i in range(len(test_labels)) if test_labels[i] != test_preds[i]]\n",
    "\n",
    "    print(diff_indices)\n",
    "    \n",
    "\n",
    "\n",
    "    # accuracy = accuracy_score(test_labels, test_preds)\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Datapath: packet_json_split/b3_p2_2_1.json\n",
      "Index: 4, Datapath: packet_json_split/b1_p1_2_1.json\n",
      "Index: 5, Datapath: packet_json_split/b2_p2_2_0_2.json\n",
      "Index: 6, Datapath: packet_json_split/b3_p1_2_0.json\n",
      "Index: 7, Datapath: packet_json_split/b5_p4_3_4.json\n",
      "Index: 8, Datapath: packet_json_split/b4_p1_3_0.json\n",
      "Index: 9, Datapath: packet_json_split/b1_p3_2_1.json\n",
      "Index: 10, Datapath: packet_json_split/b2_p5_1_1.json\n",
      "Index: 11, Datapath: packet_json_split/b5_p4_1_1.json\n",
      "Index: 12, Datapath: packet_json_split/b3_p5_1_0.json\n",
      "Index: 13, Datapath: packet_json_split/b1_p5_1_4.json\n",
      "Index: 14, Datapath: packet_json_split/b3_p3_1_0.json\n",
      "Index: 15, Datapath: packet_json_split/b1_p3_2_4.json\n",
      "Index: 17, Datapath: packet_json_split/b5_p4_3_1.json\n",
      "Index: 19, Datapath: packet_json_split/b1_p3_1_1.json\n",
      "Index: 20, Datapath: packet_json_split/b3_p1_1_4.json\n",
      "Index: 21, Datapath: packet_json_split/b2_p1_1_0.json\n",
      "Index: 22, Datapath: packet_json_split/b3_p5_1_4.json\n",
      "Index: 23, Datapath: packet_json_split/b1_p1_2_0.json\n",
      "Index: 24, Datapath: packet_json_split/b1_p5_2_4.json\n",
      "Index: 26, Datapath: packet_json_split/b2_p3_1_0_2.json\n",
      "Index: 27, Datapath: packet_json_split/b1_p1_3_0.json\n",
      "Index: 28, Datapath: packet_json_split/b1_p4_3_0.json\n",
      "Index: 29, Datapath: packet_json_split/b5_p5_2_4.json\n",
      "Index: 30, Datapath: packet_json_split/b5_p4_2_1.json\n",
      "Index: 31, Datapath: packet_json_split/b4_p4_3_4.json\n",
      "Index: 32, Datapath: packet_json_split/b5_p5_1_0_2.json\n",
      "Index: 34, Datapath: packet_json_split/b5_p3_1_4.json\n",
      "Index: 35, Datapath: packet_json_split/b4_p1_1_4.json\n",
      "Index: 36, Datapath: packet_json_split/b2_p4_3_4.json\n",
      "Index: 37, Datapath: packet_json_split/b3_p5_3_0_2.json\n",
      "Index: 38, Datapath: packet_json_split/b1_p5_2_0_2.json\n",
      "Index: 39, Datapath: packet_json_split/b4_p5_1_1.json\n",
      "Index: 40, Datapath: packet_json_split/b2_p1_3_4.json\n",
      "Index: 41, Datapath: packet_json_split/b3_p2_3_0_2.json\n",
      "Index: 42, Datapath: packet_json_split/b4_p5_3_1.json\n",
      "Index: 43, Datapath: packet_json_split/b2_p2_2_4.json\n",
      "Index: 44, Datapath: packet_json_split/b5_p1_2_0.json\n",
      "Index: 45, Datapath: packet_json_split/b1_p1_3_1.json\n",
      "Index: 46, Datapath: packet_json_split/b3_p4_1_0.json\n",
      "Index: 47, Datapath: packet_json_split/b4_p3_1_0.json\n",
      "Index: 49, Datapath: packet_json_split/b1_p3_1_4.json\n",
      "Index: 50, Datapath: packet_json_split/b4_p5_3_4.json\n",
      "Index: 51, Datapath: packet_json_split/b2_p1_2_1.json\n",
      "Index: 52, Datapath: packet_json_split/b3_p4_2_0_2.json\n",
      "Index: 53, Datapath: packet_json_split/b2_p5_3_1.json\n",
      "Index: 54, Datapath: packet_json_split/b2_p4_3_0.json\n",
      "Index: 57, Datapath: packet_json_split/b1_p5_2_1.json\n",
      "Index: 58, Datapath: packet_json_split/b5_p3_2_0.json\n",
      "Index: 59, Datapath: packet_json_split/b4_p4_1_0.json\n",
      "Index: 60, Datapath: packet_json_split/b2_p4_2_4.json\n",
      "Index: 61, Datapath: packet_json_split/b4_p2_1_4.json\n",
      "Index: 62, Datapath: packet_json_split/b4_p5_3_0.json\n",
      "Index: 63, Datapath: packet_json_split/b3_p4_3_4.json\n",
      "Index: 64, Datapath: packet_json_split/b3_p5_3_4.json\n",
      "Index: 65, Datapath: packet_json_split/b4_p2_1_1.json\n",
      "Index: 66, Datapath: packet_json_split/b2_p2_1_0_2.json\n",
      "Index: 67, Datapath: packet_json_split/b2_p1_2_4.json\n",
      "Index: 69, Datapath: packet_json_split/b5_p1_2_0_2.json\n",
      "Index: 70, Datapath: packet_json_split/b5_p2_3_1.json\n",
      "Index: 71, Datapath: packet_json_split/b5_p3_1_0.json\n",
      "Index: 72, Datapath: packet_json_split/b1_p5_3_1.json\n",
      "Index: 75, Datapath: packet_json_split/b1_p4_1_0_2.json\n",
      "Index: 76, Datapath: packet_json_split/b3_p3_2_1.json\n",
      "Index: 77, Datapath: packet_json_split/b4_p1_3_0_2.json\n",
      "Index: 78, Datapath: packet_json_split/b1_p2_1_4.json\n",
      "Index: 82, Datapath: packet_json_split/b1_p1_3_0_2.json\n",
      "Index: 83, Datapath: packet_json_split/b4_p1_1_1.json\n",
      "Index: 84, Datapath: packet_json_split/b4_p3_1_1.json\n",
      "Index: 85, Datapath: packet_json_split/b5_p1_1_0_2.json\n",
      "Index: 86, Datapath: packet_json_split/b1_p4_1_1.json\n",
      "['packet_json_split/b3_p2_2_1.json', 'packet_json_split/b1_p1_2_1.json', 'packet_json_split/b2_p2_2_0_2.json', 'packet_json_split/b3_p1_2_0.json', 'packet_json_split/b5_p4_3_4.json', 'packet_json_split/b4_p1_3_0.json', 'packet_json_split/b1_p3_2_1.json', 'packet_json_split/b2_p5_1_1.json', 'packet_json_split/b5_p4_1_1.json', 'packet_json_split/b3_p5_1_0.json', 'packet_json_split/b1_p5_1_4.json', 'packet_json_split/b3_p3_1_0.json', 'packet_json_split/b1_p3_2_4.json', 'packet_json_split/b5_p4_3_1.json', 'packet_json_split/b1_p3_1_1.json', 'packet_json_split/b3_p1_1_4.json', 'packet_json_split/b2_p1_1_0.json', 'packet_json_split/b3_p5_1_4.json', 'packet_json_split/b1_p1_2_0.json', 'packet_json_split/b1_p5_2_4.json', 'packet_json_split/b2_p3_1_0_2.json', 'packet_json_split/b1_p1_3_0.json', 'packet_json_split/b1_p4_3_0.json', 'packet_json_split/b5_p5_2_4.json', 'packet_json_split/b5_p4_2_1.json', 'packet_json_split/b4_p4_3_4.json', 'packet_json_split/b5_p5_1_0_2.json', 'packet_json_split/b5_p3_1_4.json', 'packet_json_split/b4_p1_1_4.json', 'packet_json_split/b2_p4_3_4.json', 'packet_json_split/b3_p5_3_0_2.json', 'packet_json_split/b1_p5_2_0_2.json', 'packet_json_split/b4_p5_1_1.json', 'packet_json_split/b2_p1_3_4.json', 'packet_json_split/b3_p2_3_0_2.json', 'packet_json_split/b4_p5_3_1.json', 'packet_json_split/b2_p2_2_4.json', 'packet_json_split/b5_p1_2_0.json', 'packet_json_split/b1_p1_3_1.json', 'packet_json_split/b3_p4_1_0.json', 'packet_json_split/b4_p3_1_0.json', 'packet_json_split/b1_p3_1_4.json', 'packet_json_split/b4_p5_3_4.json', 'packet_json_split/b2_p1_2_1.json', 'packet_json_split/b3_p4_2_0_2.json', 'packet_json_split/b2_p5_3_1.json', 'packet_json_split/b2_p4_3_0.json', 'packet_json_split/b1_p5_2_1.json', 'packet_json_split/b5_p3_2_0.json', 'packet_json_split/b4_p4_1_0.json', 'packet_json_split/b2_p4_2_4.json', 'packet_json_split/b4_p2_1_4.json', 'packet_json_split/b4_p5_3_0.json', 'packet_json_split/b3_p4_3_4.json', 'packet_json_split/b3_p5_3_4.json', 'packet_json_split/b4_p2_1_1.json', 'packet_json_split/b2_p2_1_0_2.json', 'packet_json_split/b2_p1_2_4.json', 'packet_json_split/b5_p1_2_0_2.json', 'packet_json_split/b5_p2_3_1.json', 'packet_json_split/b5_p3_1_0.json', 'packet_json_split/b1_p5_3_1.json', 'packet_json_split/b1_p4_1_0_2.json', 'packet_json_split/b3_p3_2_1.json', 'packet_json_split/b4_p1_3_0_2.json', 'packet_json_split/b1_p2_1_4.json', 'packet_json_split/b1_p1_3_0_2.json', 'packet_json_split/b4_p1_1_1.json', 'packet_json_split/b4_p3_1_1.json', 'packet_json_split/b5_p1_1_0_2.json', 'packet_json_split/b1_p4_1_1.json']\n"
     ]
    }
   ],
   "source": [
    "# print(data_paths(diff_indices))\n",
    "\n",
    "diff_datapaths = [data_paths[i] for i in diff_indices]\n",
    "for index in diff_indices:\n",
    "    print(f\"Index: {index}, Datapath: {data_paths[index]}\")\n",
    "print(diff_datapaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 8189,
     "status": "error",
     "timestamp": 1732684520771,
     "user": {
      "displayName": "BINGLU CHEN",
      "userId": "06455741600207729897"
     },
     "user_tz": 480
    },
    "id": "X_WFfnPiC3D6",
    "outputId": "71b1210e-2f45-4ff2-fcf8-b392e9d468ef"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3451445517.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Index: 4, Datapath: 202_packet_json/b1_p1_4.json\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Index: 4, Datapath: 202_packet_json/b1_p1_4.json\n",
    "Index: 94, Datapath: 202_packet_json/b1_p1_0_2.json\n",
    "Index: 81, Datapath: 202_packet_json/b1_p1_0.json\n",
    "Index: 65, Datapath: 202_packet_json/b5_p1_0.json\n",
    "Index: 97, Datapath: 202_packet_json/b2_p1_0.json\n",
    "Index: 62, Datapath: 202_packet_json/b1_p2_4.json\n",
    "Index: 63, Datapath: 202_packet_json/b1_p2_0.json\n",
    "Index: 48, Datapath: 202_packet_json/b1_p2_0_2.json\n",
    "b3_p2_1\n",
    "Index: 15, Datapath: 202_packet_json/b1_p3_0.json\n",
    "Index: 35, Datapath: 202_packet_json/b1_p3_0_2.json\n",
    "Index: 5, Datapath: 202_packet_json/b1_p3_4.json\n",
    "Index: 59, Datapath: 202_packet_json/b1_p4_0.json\n",
    "Index: 22, Datapath: 202_packet_json/b1_p4_4.json\n",
    "Index: 89, Datapath: 202_packet_json/b1_p4_0_2.json\n",
    "Index: 85, Datapath: 202_packet_json/b1_p5_0_2.json\n",
    "Index: 93, Datapath: 202_packet_json/b1_p5_0.json\n",
    "Index: 91, Datapath: 202_packet_json/b1_p5_4.json\n",
    "Index: 29, Datapath: 202_packet_json/b3_p5_4.json"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzl3bUNmd9ZerCBXO4n8MF",
   "mount_file_id": "1ppJfjr3KpPki2l-wT2cLvqRXCFUyovZK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "202_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
